[
  {
    "objectID": "communication/2020-12-22-modelito-sabanero/index.html",
    "href": "communication/2020-12-22-modelito-sabanero/index.html",
    "title": "Mi Modelito Sabanero",
    "section": "",
    "text": "Ayer fue #CienciaPasión2020. Como #CienciaVisión, un escaparate del humor, la música y el amor por la ciencia a todos los niveles, a los que @InmaPToro y un servidor tuvieron a bien invitarnos. El objetivo: cantar una noticia del año. La nuestra: GPT-3\n\n\n\nPero antes, queremos agradecer de CORAZÓN a la peñita maravillosa que organizan todas estas MARAVILLAS de iniciativas y que nos llaman pa mamarrachear al compás: @bynzelman@maitecicleta@hayquehacerla@PutoMikel@Nebesu_@ConchiLillo@manolux4444@sassyscience_@garirius@Victagua (fijo que me dejo alguien)\nY ahora paso a comentar algo que me han preguntado en varias ocasiones: ¿De qué co**es va la letra de la canción? Este «modelito» sabanero no es otro que GPT-3, un modelo de deep learning para el lenguaje natural que desde su publicación ha revolucionado el campo. ¡Vamos por frases!\n\n«Con mi burrito sabanero voy entrenando mi modelo,\nred neuronal del lenguaje natural».\n\nSon redes neuronales (una de las bases de la inteligencia artificial) especializadas en comprender y entender el lenguaje de los seres humanos -&gt; el «lenguaje natural».\n\n«Con tensorflow voy programando, el modelo voy compilando,\ncapa tras capa vi’apilando, el modelo voy compilando\nGPT, GPT, se llama GPT-3″\n\nTensorflow es la librería más usada para programar redes neuronales. Aunque yo soy más de PyTorch. Pero a día de hoy es el estándar de programación y en producción. Casi todos los grandes avances se pueden encontrar preparados para Tensorflow.\nEn estos modelos de deep learning, las neuronas se estructuran por «capas», grupos de neuronas que se conectan con otras capas. En nuestro caso, palabras. Si las neuronas fueran alumnos que aprenden, las capas serían filas, como comentaba en Famelab.\nY GPT-3 es el sucesor de GPT-2 y 1, modelos de redes neuronales creados para modelar el lenguaje natural, basados en una arquitectura llamada «transformer». Y que fueron un bombazo por artículos como este, completamente escritos por una Int. Artificial.\n\n«Libro tras libro descargando, la wikipedia escrapeando, todas las palabras en vectores a la entrada y a la salida»\n\nGPT-3 se entrenó utilizando millones de libros de dominio público, artículos científicos y la wikipedia al completo. Referencias: https://arxiv.org/abs/2005.14165\n\n«Atención, atención, mecanismo de atención»\n\n\n\n\nMecanismo de atención en imágenes\n\n\nLa gran innovación de los transformers es el «mecanismo de atención», una herramienta que se construye en las redes neuronales, que permite a la red centrarse en unas entradas más que en otras, les presta más «atención».\nEl mecanismo de auto-atención (self-attention) se presentó en el paper «Attention is all you need», en el NeurIPS 2017, paper que, por cierto, también aparece en el vídeo: https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\n\n«Tuki tuki tuki tuki,_\ntuki tuki tuki ta\najusta bien el modelo que lo vamos a entrenar»\n\nTremendo cumbión. Pues eso, a preparar un modelo de red «tó polluo», que si no, no funciona.\n\n«Tuki tuki tuki tuki,\ntuki tuki tuki ta,\na ver si pasa el test de Turing, que lo vamos a petar»\n\nEl test de Turing es un test diseñado por Alan Turing, que permitiría decir cuando una máquina es inteligente. Esto sucedía en un entorno experimental en el que humanos interactuaban vía texto en conversación con otros humanos, o podría ser con máquinas. Si un ser humano era incapaz de discernir si estaba hablando con una máquina o con otro ser humano, se dice que ese algoritmo ha pasado el Test de Turing.\n\n«Con mi burrito sabanero vi’entrenando mi transformer\nEn arXiv, en arXiv, puedes encontrarme allí\nen github, en github puedes encontrarme allá»\n\nhttp://arXiv.org es una web donde muchos científicos publican sus avances antes de enviarlos a revistas. Son conocidos como pre-prints, y aunque todavía no han pasado el proceso de revisión, es una forma muy rápida (y gratuita) de acceder al conocimiento que se está produciendo.\nY Github, pues eso.. @github Un servidor de Git, un sistema de control de versiones donde los desarrolladores de software centralizar el control de los cambios que hacen a su código. Allí están centralizados en «repositorios», lugares desde donde después se puede distribuir el código y contribuir a una ciencia más abierta.\n\n«Muy pronto los veremos integraos en una aplicación\ndentro del Office generando textos con gran precisión\ny en robots, en robots, robots de conversación»\n\nLa aplicación directa: integrar los modelos para generar, aumentar productividad e interactúar con humanos. Ya hay modelos similares que se están implementando en aplicaciones como Photoshop para ayudar en la productividad de imagen. Y para el lenguaje natural, herramientas como DeepL translate ya tienen una gran difusión para traducir textos. Es sólo cuestión de tiempo que se integren en los paquetes de software más usados.\n\n«Y con lo caro que se ha puesto el precio del kilovatio\ny lo que gasta en entrenarlo, Endesa se está forrando.\nGPU, GPU, la factura de la luz»\n\nEl consumo energético: ésta es la cara B de todo el boom del Deep Learning. El consumo de las GPU, o las unidades de procesamiento gráfico que se utilizan en redes neuronales es mucho más elevado que el de los procesadores normales. Se dice que entrenar GPT-3 consumió tanto como conducir un coche de la tierra a la luna, y volver.\n\n«Perrea con Ada Lovelace, lo baila Alan Turing,\nlo está bailando Hinton perreando a LeCun.\nPerreamos tan a ritmo nos cargamos la ley de Moore»\n\nAda Lovelace (1815-1852) se considera la primera programadora de la historia. Fue hija del poeta inglés Lord Byron, y de la también matemática y activista social Anna Isabella Byron. Fue educada, entre otras, por la matemática Mary Somerville. Tuvo una buena relación con Charles Babbage, a quien ayudó a diseñar el funcionamiento teórico de la «máquina diferencial», describiendo en sus «Notas» con un lenguaje muy técnico cómo funcionaría esta máquina, distinguiendo con claridad los conceptos de datos y procesamiento. Pero para más datos, este hilo es genial:\nDe Alan Turing, poco se puede decir que no se haya dicho ya. Padre de la Inteligencia Artificial, descifró Enigma (la máquina de los Nazis) y fue condenado al ostracismo por su propio gobierno al descubrir su homosexualidad. Acabó suicidándose.\nPor último, Hinton y LeCun son considerados «padres» de la explosión del deep learning.\nCon esto, y un bizcocho… ¡A PERREAR, PERREAR LA INTELIGENCIA ARTIFICIAL!\nGracias a los que habéis llegado hasta aquí, y a los que habéis hecho posible esta canción, este hilo y esta alegría que llevo dentro desde #cienciapasion2020 !!!\n\n\n\nCitationBibTeX citation:@online{martinez-murcia2020,\n  author = {Martinez-Murcia, F.J.},\n  title = {Mi {Modelito} {Sabanero}},\n  date = {2020-12-20},\n  url = {https://pakitochus.github.io/fjmartinezmurcia.es/COMMUNICATION/2020-12-22-modelito-sabanero/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMartinez-Murcia, F.J. 2020. “Mi Modelito Sabanero.”\nDecember 20, 2020. https://pakitochus.github.io/fjmartinezmurcia.es/COMMUNICATION/2020-12-22-modelito-sabanero/."
  },
  {
    "objectID": "communication.html",
    "href": "communication.html",
    "title": "Communication",
    "section": "",
    "text": "Mi Modelito Sabanero\n\n\n\ncienciavision\n\n\nmusica\n\n\ncomunicacion\n\n\nscenio\n\n\nia\n\n\n\nUna oda a GPT-3\n\n\n\nF.J. Martinez-Murcia\n\n\nDec 20, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDivulgamiento y Confinación – El Musical\n\n\n\nciencia\n\n\nscenio\n\n\ndivulgacion\n\n\nhumor\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\nDec 11, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl P-Valor\n\n\n\nciencia\n\n\ndivulgacion\n\n\nhumor\n\n\nscenio\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\nMay 23, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nPodcast Efecto Moiré - Episodio 1\n\n\n\nciencia\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nDesgranando la Ciencia 6: RepliGANtes\n\n\n\nciencia\n\n\ndivulgacion\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\nJan 5, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n¡Las máquinas nos quitan el trabajo! (de nuevo)\n\n\n\nciencia\n\n\ndivulgacion\n\n\n\n\n\n\n\n\n\n\nSep 5, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nBarber’s Science en la clausura de @GranadaCiencia\n\n\n\nciencia\n\n\ndivulgacion\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\nJun 2, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nPint of Science Granada 2019\n\n\n\nciencia\n\n\ndivulgacion\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\nMay 23, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nLa Canción del Silicio\n\n\n\nciencia\n\n\ndivulgacion\n\n\nmusica\n\n\n\n\n\n\n\nF.J. Martinez-Murcia\n\n\nMar 11, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nY llegó la Final\n\n\n\nciencia\n\n\ndivulgacion\n\n\nhumor\n\n\n\n\n\n\n\n\n\n\nMay 21, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nEn la Feria de la Ciencia de Guadalajara\n\n\n\ndivulgacion\n\n\nhumor\n\n\n\n\n\n\n\n\n\n\nMay 13, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n¡Finalista en Famelab!\n\n\n\nciencia\n\n\ndivulgacion\n\n\nhumor\n\n\n\n\n\n\n\n\n\n\nApr 10, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nConoce a los #Famelabers\n\n\n\nciencia\n\n\ndivulgacion\n\n\n\n\n\n\n\n\n\n\nApr 2, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nSemifinalista en Famelab 2018!\n\n\n\nciencia\n\n\ndivulgacion\n\n\nhumor\n\n\n\n\n\n\n\n\n\n\nMar 13, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nMi charla de Three-Minute Thesis\n\n\n\nsin-categoria\n\n\n\n\n\n\n\n\n\n\nApr 10, 2017\n\n\n\n\n\n\n\n\n\n\n\n\nEl 3MT Granada\n\n\n\ndivulgacion\n\n\n\n\n\n\n\n\n\n\nMar 3, 2017\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Currently I research in Information Technology, inside the interdisciplinary field of Computer Aided Diagnosis, Image-based diagnosis and Statistical and Digital Signal Processing. A provisional title for all this research is Computed Aided Diagnosis for the detection of Neurodegenerative Disorders using Medical Imaging.\nDuring this period I have belonged to the Signal Processing and Biomedical Applications (SiPBA) research group, and I have written or contributed to several publications.\n\n\nResearch projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLATiDOS\n\n\n\npython\n\n\nproject\n\n\n\nLATent variable models to Determine the Onset of neurodegenerative Symptoms.\n\n\n\nF.J. Martinez-Murcia\n\n\nSep 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrainSimulator\n\n\n\npython\n\n\nproject\n\n\n\nFunctional brain image synthesis using the KDE or MVN distribution.\n\n\n\nF.J. Martinez-Murcia\n\n\nNov 30, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoctoral Thesis\n\n\n\npython\n\n\nmatlab\n\n\nthesis\n\n\n\nFStatistical Neuroimage Modeling, Processing and Synthesis based on Texture and Component Analysis: Tackling the Small Sample Size Problem..\n\n\n\nF.J. Martinez-Murcia\n\n\nJun 1, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSignificance Weighted Principal Component Analysis (SWPCA)\n\n\n\npython\n\n\nproject\n\n\n\nSignificance Weighted Principal Component Analysis (SWPCA) is a technique (1) developed to parse out the influence of a categorical variable that introduces variability in a…\n\n\n\nF.J. Martinez-Murcia\n\n\nOct 24, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpherical Brain Mapping\n\n\n\npython\n\n\nmatlab\n\n\nproject\n\n\n\nThe Spherical Brain Mapping (SBM) is a feature extraction and visualization framework intended to map the internal structures and features of the brain onto a 2D image that…\n\n\n\nF.J. Martinez-Murcia\n\n\nSep 15, 2016\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/2020-04-14-CyS-UMA/index.html",
    "href": "teaching/2020-04-14-CyS-UMA/index.html",
    "title": "Circuitos y Sistemas - Canal de Youtube",
    "section": "",
    "text": "Playlist\nEn 2020 impartía la segunda parte de la asignatura de Circuitos y Sistemas, en la E.T.S. de Ingeniería de Telecomunicación de la Universidad de Málaga. Dado el impacto de la pandemia y confinamiento mediante, no se podía realizar de modo presencial. Así que había dos opciones: conectarse a meet/zoom o generar contenido más elaborado en forma de vídeos docentes.\nAl final (pobre ignorante) opté por esta segunda opción, para dejar que los alumnos y demás interesados pudieran acceder al contenido bajo demanda, y creé el canal de youtube UMA-CYS-GISE, acrónoimo de «Circuitos y Sistemas» – Grado en Ingeniería de Sistemas Electrónicos.\nEl resultado es una serie de vídeos cubriendo los temas que me habrían tocado en su momento, comenzando por el análisis de la respuesta en frecuencia de un circuito electrónico, y pasando por diferentes temas como los filtros de diferentes tipologías y órdenes, los diagramas de bode, implementaciones electrónicas y el análisis de cuadripolos."
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Throughout the years, I’ve taught more than 450h of undergrad classes, including:\n\nIndustrial Robotics\nDigital Signals\nLineal Systems and Circuit and Systems\nDeep Learning for Digital Signal Processing\n\nFurthermore, I’ve supervised 9 final degree/master projects, and currently supervise 2 PhD theses.\n\nFeatured material\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¿Qué es un filtro?\n\n\n\ndocencia\n\n\npython\n\n\nsigjnal processing\n\n\ncomputer vision\n\n\n\nVídeo divulgativo sobre filtros. Tipos, ecuaciones y visualización.\n\n\n\nF.J. Martinez-Murcia\n\n\nJan 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTutorial Deep Learning con Pytorch\n\n\n\ndocencia\n\n\npython\n\n\ndeep learning\n\n\ncomputer vision\n\n\n\nTutorial de pytorch para la asignatura Tratamiento Digital de Voz e Imagen, del grado en Sonido de Imagen de la Universidad de Málaga..\n\n\n\nF.J. Martinez-Murcia\n\n\nMay 11, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCircuitos y Sistemas - Canal de Youtube\n\n\n\ndocencia\n\n\nmatlab\n\n\npython\n\n\ncircuitos\n\n\nsistemas\n\n\n\nMaterial docente audiovisual para el seguimiento virtual y bajo demanda de la asignatura Circuitos y Sistemas de la Universidad de Malaga.\n\n\n\nF.J. Martinez-Murcia\n\n\nApr 14, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Carpentry Workshop en el IFT e ICMAT del CSIC\n\n\n\nciencia\n\n\n\n\n\n\n\nF.J. Martinez-Murcia\n\n\nDec 4, 2018\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/2020-04-14-CyS-UMA/index.html#tema-3",
    "href": "teaching/2020-04-14-CyS-UMA/index.html#tema-3",
    "title": "Circuitos y Sistemas - Canal de Youtube",
    "section": "Tema 3",
    "text": "Tema 3\n\nTema 3 - Cap 1 - Respuesta en Frecuencia\nTema 3 - Cap 2 - ¿Qué es un filtro?\nTema 3 - Cap 3 - Filtro de paso baja de primer orden\nTema 3 - Cap 4 - Filtro de paso alta de primer orden\nTema 3 - Cap 5 - Filtros de Paso Baja 2º Orden\nTema 3 - Cap 6 - Filtros de paso alto de 2º orden\nTema 3 - Cap 7 - Filtros de paso banda de 2º orden\nTema 3 - Cap 8 - Filtros de banda eliminada de 2º orden\nTema 3 - Cap 9 - Diagramas de Bode (introducción)\nTema 3 - Cap 10 - Diagrama de Bode con puntos singulares reales\nTema 3 - Cap 11 - Diagramas de Bode con puntos singulares complejos conjugados\nTema 3 - Cap 12 - Diseño de filtros a partir del diagrama de Bode\nTema 3 - Cap 13 - Respuesta en frecuencia del amplificador operacional"
  },
  {
    "objectID": "teaching/2020-04-14-CyS-UMA/index.html#tema-4",
    "href": "teaching/2020-04-14-CyS-UMA/index.html#tema-4",
    "title": "Circuitos y Sistemas - Canal de Youtube",
    "section": "Tema 4",
    "text": "Tema 4\n\nTema 4 - Cap 1 - Bipuertos\nTema 4 - Cap 2 - Parámetros G y H\nTema 4 - Cap 3 - Conexión en serie\nTema 4 - Cap 4 - Análisis de circuitos con bipuertos"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "F.J. Martinez-Murcia",
    "section": "",
    "text": "Telecommunications Engineer and PhD in Information and Communication Technologies from the University of Granada. Currently, Ramon y Cajal researcher at the University of Granada, specialising in signal processing and analysis and medical brain imaging. Finalist in Famelab 2018 and winner of 3-Minute Thesis Granada 2017. Musician and hopeless geek."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "F.J. Martinez-Murcia",
    "section": "Education",
    "text": "Education\n\nTelecommunications Engineer (2010) | University of Granada\nMsC in Computer and Network Engineering (2011) | University of Granada\nPhD in Information and Communications Technology (2017) | University of Granada"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "F.J. Martinez-Murcia",
    "section": "Experience",
    "text": "Experience\n\nCAS Research Group Fellow (2023 - ) | Ludwig-Maximilien Universität München\nRamon y Cajal fellow (2023 - ) | University of Granada\nJuan de la Cierva – incorporación fellow (2020-2022) | University of Granada\nJose Castillejo fellow (2019) | Ludwig-Maximilien Universität München\nJuan de la Cierva – formación fellow (2019-2020) | University of Malaga\nPostdoctoral researcher (2018-2019) | DaSCI – Andalusian Institute on Data Science and Computational Intelligence\nPredoctoral researcher (2014-2017) | University of Granada\nWebsite manager, front-end development (2010-2011) | Language4you education S.L."
  },
  {
    "objectID": "teaching/2021-10-01-DeepLearning/index.html",
    "href": "teaching/2021-10-01-DeepLearning/index.html",
    "title": "Tutorial Deep Learning con Pytorch",
    "section": "",
    "text": "Formato libro  Repositorio\nEn 2020 tuve la suerte de poder realizar una práctica de introducción al Deep Learning utilizando pytorch para que lo usaran los alumnos del grado en Sonido e Imagen de la Universidad de Málaga.\nPosteriormente lo edité en formato libro (bastante fácil siendo todos notebooks de jupyter) y lo colgué en github.\n\nOrganización del tutorial\nEste tutorial consta de tres partes, cada una de ellas es un notebook de jupyter, o sea, un documento como el que estás visualizando en este momento. Las partes son las siguientes:\n\nParte 0: Introducción al Deep Learning. Es este notebook, preparatorio de la práctica mediante realización guiada en el que se tratarán:\n\nUnas pinceladas a las matemáticas y la historia de las redes neuronales\nInformación sobre qué es y cómo instalar el software necesario para esta práctica: la distribución de python 3 Anaconda, la librería de computación tensorial PyTorch y la plataforma de notebooks jupyter.\nUna introducción a la computación matricial en python con pytorch, que en muchas cosas se parece a matlab.\n\nParte 1: El Perceptrón Multicapa. En esta parte se introduce el perceptrón multicapa (Multi-Layer Perceptron o MLP), la red neuronal más básica que podemos construir. Se verán detalladamente las pautas a seguir para crear, entrenar y evaluar una red neuronal utilizando la librería pytorch. Será una realización guiada, sin problemas a resolver.\nParte 2: Redes Neuronales Convolucionales. Esta parte será la entregable de la práctica de redes. En ella veremos las redes neuronales convolucionales, que son la herramienta más potente que existe a día de hoy para el procesado de imagen. Se utilizan en coches autónomos, en la búsqueda de imágenes de google, diagnóstico de enfermedades, interpretación del lenguaje, y muchas más aplicaciones. Veremos las particularidades de estas redes y cómo se implementan cada una. La segunda parte de este notebook será el problema a resolver: crear y entrenar una red convolucional para la detección de dígitos escritos a mano.\n\n\n\n\n\nCitationBibTeX citation:@online{martinez-murcia2020,\n  author = {Martinez-Murcia, F.J.},\n  title = {Tutorial {Deep} {Learning} Con {Pytorch}},\n  date = {2020-05-11},\n  url = {https://pakitochus.github.io/fjmartinezmurcia.es/teaching/2021-10-01-DeepLearning/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMartinez-Murcia, F.J. 2020. “Tutorial Deep Learning Con\nPytorch.” May 11, 2020. https://pakitochus.github.io/fjmartinezmurcia.es/teaching/2021-10-01-DeepLearning/."
  },
  {
    "objectID": "teaching.html#some-featured-material",
    "href": "teaching.html#some-featured-material",
    "title": "Teaching",
    "section": "Some featured material",
    "text": "Some featured material"
  },
  {
    "objectID": "communication/2017-03-03-el-3mt-granada/index.html",
    "href": "communication/2017-03-03-el-3mt-granada/index.html",
    "title": "El 3MT Granada",
    "section": "",
    "text": "Three minute thesis es una iniciativa internacional con sólo un objetivo: contar tu tesis en tres minutos, sólo con ayuda de una diapositiva estática, para una audiencia inteligente pero no especializada. Es un reto mayúsculo para los que nos pasamos horas detrás de una pantalla de ordenador, intentando traducir líneas y líneas de código a un lenguaje especializado que pueda llegar a otro público igualmente especializado. Es divulgación, con todo lo que ello conlleva.\nY a mí me atrae muchísimo la divulgación. Era la oportunidad de oro para tirarme de lleno a la piscina y aprender. Cuando me tiré sin mirar si había agua siquiera allá por octubre no pensé lo que me iba a encontrar. Ha sido una experiencia inolvidable, donde he conocido a gente extremdamente interesante que comparte estos mismos intereses, donde he aprendido muchísimas cosas de los mejores profesionales, y que me llevo como mayor premio que atesoraré toda la vida. Creo que es el principio de una hermosa historia.\n[caption id=“attachment_586” align=“aligncenter” width=“764”] Participantes en la primera fase del 3MT[/caption]\nY sí, al final gané, en la versión local. Pero yo ya había ganado con todo lo demás. No os puedo transmitir lo maravillosa que ha sido toda esta experiencia. Simplemente tengo palabras de agradecimiento a todos los que lo han hecho posible. A la escuela de posgrado, la universidad y el vicerrectorado de internacionalización, y muy especialmente a Maria Teresa Bajo, que organizaron la competición con muchísimo amor y dedicación. A los profesores de todos los cursos de formación que hemos tenido, de divulgación y de inglés: Meca, Susana, Emilio y Carlos, que ha sido la constante en esta ecuación. Y por supuesto, a todos esos maravillosos concursantes, con los que hemos construido una experiencia de aprendizaje inolvidable, y que espero nos sigamos viendo mucho más allá de que termine este concurso y otros.\nPróxima parada… Famelab? Quien sabe!"
  },
  {
    "objectID": "communication/2017-04-10-mi-charla-de-three-minute-thesis/index.html",
    "href": "communication/2017-04-10-mi-charla-de-three-minute-thesis/index.html",
    "title": "Mi charla de Three-Minute Thesis",
    "section": "",
    "text": "https://www.youtube.com/watch?v=jAu_Gj3oMAU"
  },
  {
    "objectID": "communication/2018-03-13-semifinalista-en-famelab-2018/index.html",
    "href": "communication/2018-03-13-semifinalista-en-famelab-2018/index.html",
    "title": "Semifinalista en Famelab 2018!",
    "section": "",
    "text": "Esto es una noticia corta. Básicamente, soy semifinalista en Famelab 2018, el concurso de monólogos científicos por excelencia en España.  Es una oportunidad increíble para aprender de los mejores, y con lo que me gusta a mi la farándula, ya ni te cuento."
  },
  {
    "objectID": "communication/2018-04-02-conoce-a-los-famelabers/index.html",
    "href": "communication/2018-04-02-conoce-a-los-famelabers/index.html",
    "title": "Conoce a los #Famelabers",
    "section": "",
    "text": "Este domingo, a iniciativa (y gracias a) nuestra anfitriona y compañera Laura Parro, de Viajando por Planetas, nos juntamos en un directo de Youtube parte de los semifinalistas de Famelab 2018, para hablar sobre divulgación, ciencia, monólogos y muchas más cosas. Con la propia Laura, Marina, Carlos, Ignacio, Jose Luis, Eder y Dani. No os lo podéis perder!\nhttps://www.youtube.com/watch?v=etYogFENvM0\nhttps://twitter.com/VxPlanetas/status/980541101542125569"
  },
  {
    "objectID": "communication/2018-04-10-finalista-en-famelab/index.html",
    "href": "communication/2018-04-10-finalista-en-famelab/index.html",
    "title": "¡Finalista en Famelab!",
    "section": "",
    "text": "Pues resulta que finalmente he pasado a la final de Famelab, el concurso de monólogos científicos por antonomasia. Fíjate que nunca pensé hacer un monólogo (y mucho menos científico), pero tras la insistencia de Carlos Centeno, aquí estoy, y ¡hemos venido a jugar!\nAsí que estoy muy honrado de estar entre los ocho finalistas, y a los que se quedaron fuera, recomendaros que echéis un vistazo a sus monólogos porque son geniales y merecían totalmente seguir con nosotros. Laura, Jose Luis, Marina, y Carlos, ¡os echaremos mucho de menos!\nY para el que le interese, este es mi monologuillo:\nhttps://www.youtube.com/watch?v=4xaPxNPr43w"
  },
  {
    "objectID": "communication/2018-05-21-y-llego-la-final/index.html",
    "href": "communication/2018-05-21-y-llego-la-final/index.html",
    "title": "Y llegó la Final",
    "section": "",
    "text": "Finalmente, tras la maravillosa experiencia de la semifinal de Famelab, tuvimos unas cuantas jornadas más de convivencia y aprendizaje, incluyendo la genial Masterclass de  James Piercy, un conocido especialista en comunicación científica con un CV envidiable. Y tras ella, el momento más esperado, la FINAL.\nHace tiempo que, para mi, Famelab dejó de ser un concurso para pasar a ser una experiencia vital, en la que he conocido gente maravillosa, he aprendido muchísimo sobre ciencia y comunicación, y sobre todo, me lo he pasado genial. Y ha brindado oportunidades únicas, como esta gala final de Famelab en la mítica Sala Galileo, presentada por Ana Morgade, y a la que incluso asistieron los Reyes de España. Y mi abuelo, que ya es mucho decir.\nY este es el monólogo con el que me lucí (más o menos) frente a tan insigne públco:\nhttps://www.youtube.com/watch?v=LQMRskbYEHs\nNo fue tan potente (para mi gusto) como el primero, pero me divertí mucho haciéndolo y aprendí bastante. Finalmente, el ganador fue aplastantemente el grandísimo Juan Margalef, seguidos por Raquel Medialdea e Ignacio Crespo (al que recomiendo seguir, ya que tiene una larga trayectoria en divulgación, y con todo esto va a ir a muuucho más). Premios muy merecidos, como los merecían todos y cada uno.\nY pa muestra, una de las fotos que más transmite el espíritu que nos ha contagiado este Famelab:\n\n¡Mil gracias a todos!"
  },
  {
    "objectID": "communication/2018-05-13-en-la-feria-de-la-ciencia-de-guadalajara/index.html",
    "href": "communication/2018-05-13-en-la-feria-de-la-ciencia-de-guadalajara/index.html",
    "title": "En la Feria de la Ciencia de Guadalajara",
    "section": "",
    "text": "En la que es mi primera experiencia como monologuista fuera del círculo académico (3MT y Famelab), me llamaron para actuar en la I Feria de la Ciencia de Guadalajara. Para mi es todo un honor haber participado, y quiero agradecer a todos los que lo hicieron posible, con especial mención a Juan Pablo Guzmán, un adverso de pro, que lo organizó todo a la perfección.\n\n\n\nAquí unos tweets:"
  },
  {
    "objectID": "communication/2019-03-11-la-cancion-del-silicio/index.html",
    "href": "communication/2019-03-11-la-cancion-del-silicio/index.html",
    "title": "La Canción del Silicio",
    "section": "",
    "text": "Esto es una respuesta al reto del International Year of the Periodic Table, que me propusieron en twitter. Como ingeniero de teleco, mi elemento favorito es el silicio. Y con todo el amor que le tengo, le he compuesto una canción #IYPT2019\n\nY el vídeo final, puesto que arreglé ciertos problemas con el vídeo originalmente colgado:"
  },
  {
    "objectID": "communication/2019-05-23-pint-of-science-granada-2019/index.html",
    "href": "communication/2019-05-23-pint-of-science-granada-2019/index.html",
    "title": "Pint of Science Granada 2019",
    "section": "",
    "text": "Era la primera vez para muchas cosas, y ha sido mágica. En primer lugar porque de un absurdo reto en twitter he montado un cuarteto de armonía vocal, o BarberShop Quartet que parece que está despegando a pasos agigantados. En segundo lugar porque era mi primera charla divulgativa de más de 15 minutos, y estaba muy nervioso por, entre otras cosas, pasarme o quedarme corto, o aburrir soberanamente al personal.\n\nComenzando la presentación\nParece que ninguno de mis temores se cumplió. Al parecer la charla gustó bastante, empezando con una estructura similar a mi primer monólogo en Famelab (el bueno), pero con mayor profundidad, con ayuda de imágenes, y explicando numerosas aplicaciones.. ¡E incluso hablando de arquitecturas más complejas como Autoencoders o GANs! En fin, desde aquí quiero agradecer muchísimo a todos los que asistieron, a los que vinieron a apoyar muy fuertemente (GRACIAS), y muy en especial a la organización de Pint of Science Granada, en especial a María, Óscar y Sara, extensible a todos los que lo hicieron posible.\n\nBebiendo agua como un cosaco para que se me pasara la bocaseca de los nervios. #bocasecaman\nY, pese al éxito individual que supuso la charla, y que me demostró que también soy capaz de estar hablando tres cuartos de hora de redes neuronales sin ser muy pelmazo, hay un punto que me picó ya la vena/ego artístico-farandulero: Barber’s Science.\n\nPrimero fue la canción del silicio. Luego, literalmente dada mi “afición a la farándula”, María me pidió preparar algo para el intermedio. Mi primera opción fue llevar un piano y cantar esa y alguna otra canción absurdocientífica. Pero llevar un piano al Realejo esconde cierta imposibilidad logística que me hizo echarme atrás. Y recordé que uno de mis mayores sueños era cantar en un cuarteto Barbershop. Así que dije: “tengo un mes, ¿por qué no?”. Y así se hizo. Gracias a Ángel, Diego y Alberto, que me siguieron en esta aventura, y que finalmente han hecho posible Barber’s Science, un nuevo proyecto de divulgación mediante la música, y que a día de hoy ya tiene varias actuaciones confirmadas. Todo un éxito y un placer poder juntar, por fin y ante el público, la música y la ciencia, algo que llevaba muchísimo tiempo queriendo hacer.\n\nY esto ha sido toda mi aventura en el Pint of Science. Algo maravilloso que recordar. GRACIAS."
  },
  {
    "objectID": "communication/2019-06-02-barbers-science-en-la-clausura-de-granadaciencia/index.html",
    "href": "communication/2019-06-02-barbers-science-en-la-clausura-de-granadaciencia/index.html",
    "title": "Barber’s Science en la clausura de @GranadaCiencia",
    "section": "",
    "text": "¡Pelotazo! Con apenas un mes de vida, Barber’s Science se codeó con los grandes de la divulgación en el evento de clausura de Granada, ciudad de la ciencia y la innovación. ¡Todo un grandísimo honor!\nPero empecemos por el principio. ¿Qué es @granadaciencia? En 2017 el ministerio ortorgó a la ciudad de Granada el nombramiento de “Ciudad de la Ciencia y la Innovación” por ser un referente de la investigación multidisciplinar. Para celebrarlo, el ayuntamiento, universidad, CSIC y demás instituciones científicas, elaboraron un programa de actividades de divulgación para compartir toda esta experiencia con la ciudadanía.\nHa sido un año lleno de actividades de divulgación, en la feria del libro, feria de la ciencia, charlas en el LemonRock, etc, con un grandísimo éxito. Y es aquí, justo cuando se clausura el curso y el ciclo de actividades, que nos llama Oscar (cómo no) para participar en el evento final. ¡Y nosotros ilusionadísimos!\n\nY pa muestra un botón:\nhttps://twitter.com/granadaciencia/status/1134896920755879936\nHicimos las tres obras de “John Moretropier” que habíamos preparado: Canción del Silicio, El enlace más fuerte y Mendeleiev. Personalmente me dejó muy buen sabor de boca, y pude conocer a auténticos referentes en la divulgación como el grandísimo Daniel Guirado!\nFue una tarde muy intensa y muy emocionante. Y aquí, algunas fotos, cortesía de @SaseAmaro:"
  },
  {
    "objectID": "communication/2019-09-05-las-maquinas-nos-quitan-el-trabajo-de-nuevo/index.html",
    "href": "communication/2019-09-05-las-maquinas-nos-quitan-el-trabajo-de-nuevo/index.html",
    "title": "¡Las máquinas nos quitan el trabajo! (de nuevo)",
    "section": "",
    "text": "Siempre es un placer que me inviten a saraos, pero ya que lo hagan como “invited speaker” son palabras mayores. Y eso es lo que me pidieron para el XX ENEM Granada. Que llegara y soltara una sarta de mis chominaicas. Y encima de las tablas, frente a cientos de estudiantes y post-estudiantes de matemáticas de todo el país.\n¿Nervios? Muchísimos. Es un público muy exigente, al que le tenía que hablar de inteligencia artificial, una de las ramas más importantes de la aplicación de matemáticas, y puede que donde muchos encuentren trabajo en el futuro. Pero a la vez, apenas se pasa de puntillas durante la carrera, y según confirmé después, la mayor parte de lo que aprenden lo hacen por su cuenta.\n¿El reto? Hablar de machine learning a gente que tiene unos conocimientos y una base de matemáticas significativamente superior a la mía. Pero también desde una perspectiva divulgativa.\n\n\n\n\nNo sé si lo conseguí o no. Lo mejor es que me llevo una experiencia nueva, me atreví con mates (que no me había dado por ahí), hice incluso simulaciones computacionales para visualizar las redes neuronales, y me lo pasé genial.\nNo puedo hacer otra cosa que agradecer a la organización, especialmente a Sara, por invitarme, por las fotos y por tratarme TAAAAN bien. A los asistentes, por su atención y por luego llenarme de preguntas, a las cuales a veces ni siquiera sabía yo responder (he hecho mis deberes después, así es como se aprende más). Y por invitarme a la cena, que ya sabéis como somos los músicos, vamos a los saraos por la comida na más."
  },
  {
    "objectID": "communication/2020-01-05-desgranando-la-ciencia-6-repligantes/index.html",
    "href": "communication/2020-01-05-desgranando-la-ciencia-6-repligantes/index.html",
    "title": "Desgranando la Ciencia 6: RepliGANtes",
    "section": "",
    "text": "He tenido el placer de asistir a Desgranando Ciencia 6 por primera vez como ponente! Hablo de Deep Fakes y de la tecnología que está detrás de los mismos: las redes generativas adversarias, conocidas como GANs, todo ambientado en Blade Runner, por supuesto. Espero que os guste!\nhttps://www.youtube.com/watch?v=OQLFuV3FBQA"
  },
  {
    "objectID": "communication/2020-02-06-podcast-efecto-moire-episodio-1/index.html",
    "href": "communication/2020-02-06-podcast-efecto-moire-episodio-1/index.html",
    "title": "Podcast Efecto Moiré - Episodio 1",
    "section": "",
    "text": "En el marco del programa de formación para docentes de la UMA, estoy haciendo un curso de edición de Video y Podcast para su uso docente. Como práctica, he preparado un programa de introducción a las redes neuronales, que se utilizará como introducción en la práctica 5 de la asignatura Tratamiento digital de Voz e Imagen, del grado de Ingeniero de Telecomunicación, especialidad en sistemas de telecomunicación.\nPodéis escuchar el primer episodio, sobre las redes neuronales en el siguiente enlace:\nEste es el enlace para descargar: https://www.ivoox.com/47414116. Pero os dejo el archivo para escuchar aquí:\nIr a descargar\nY también hemos preparado un vídeo inspiracional:\nhttps://www.youtube.com/watch?v=gWw88W7fn54"
  },
  {
    "objectID": "communication/2020-05-23-el-p-valor/index.html",
    "href": "communication/2020-05-23-el-p-valor/index.html",
    "title": "El P-Valor",
    "section": "",
    "text": "En ciencia, la significación, o decir que algo es “Significativo” es un término mucho más preciso que en el lenguaje natural. Es una medida de la probabilidad de que un resultado sea por azar, y se utiliza constantemente para valorar los resultados de nuestros experimentos. Esta significación nos permite, por ejemplo, decir que un fármaco es más efectivo que el placebo, saber con seguridad que hemos detectado el bosón de Higgs, o decir que los carteros tienen un testículo sustancialmente más caliente que otro (si, no sabemos de donde salió la financiación, pero…).\nY para cuantificar la significación, nace el concepto de p-value, o “valor p” en castellano. Se trata de uno de los conceptos más utilizados en la ciencia moderna, a la vez que uno de los peor interpretados y entendidos. El p-valor cuantifica la probabilidad de que un resultado sea por azar. Si esta probabilidad es menor que un cierto umbral (normalmente 0.05), se considera que este resultado es “significativo”, y por tanto se da por bueno.\nEste procedimiento es justo el que se ha puesto en tela de juicio más de una vez, e incluso la prestigiosa revista Nature ha concluido que casi la mitad de los estudios que lo utilizan lo malinterpretan, abogando por intentar que progresivamente caiga en desuso.\nPero en la época de nuestro John Moretropier, era un campo recién explorado a manos de grandes matemáticos, primero de Fisher y luego Pearson, Neymann y muchos otros. Y dado su entusiasmo ante tamaño descubrimiento, escribió la siguiente oda a la significación estadística: el p-valor.\nhttps://www.youtube.com/watch?v=1GtGWUUeTTU"
  },
  {
    "objectID": "communication/2020-12-11-divulgamiento-y-confinacion-el-musical/index.html",
    "href": "communication/2020-12-11-divulgamiento-y-confinacion-el-musical/index.html",
    "title": "Divulgamiento y Confinación – El Musical",
    "section": "",
    "text": "Ayer fue Trivulgando, un evento de divulgación nacional que se nos va haciendo mayor. Por la situación actual, este año había una temática subyacente a todas las ponencias: la pandemia, y cómo esta ha influido en la sociedad, la ciencia y la divulgación.\nPara poner la nota farandulera final, nos llamaron a Inma Pérez y un servidor, así que.. ¿qué mejor idea que hacer un recorrido por los diferentes aspectos de la Covid?\n2020 ha sido muy especial. Y se merecía una canción. ¿O un musical?"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Alcalá la Real: año de construcción de edificios\n\n\n\n\n\n\n\nciencia\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2021\n\n\n\n\n\n\n  \n\n\n\n\nUn proyecto teutón\n\n\n\n\n\n\n\nciencia\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2019\n\n\n\n\n\n\n  \n\n\n\n\nLa movilidad internacional y el sistema científico español\n\n\n\n\n\n\n\nciencia\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTaller de comunicación 3MT\n\n\n\n\n\n\n\nciencia\n\n\ndivulgacion\n\n\n\n\n\n\n\n\n\n\n\nFeb 5, 2019\n\n\n\n\n\n\n  \n\n\n\n\nJupyter Lab, un nuevo IDE para python\n\n\n\n\n\n\n\nciencia\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2018\n\n\n\n\n\n\n  \n\n\n\n\nJugando con Logos\n\n\n\n\n\n\n\nvisual-thinking\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2018\n\n\n\n\n\n\n  \n\n\n\n\nBohemian Rhapsody\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2017\n\n\n\n\n\n\n  \n\n\n\n\nSíntesis de imágenes cerebrales en Python\n\n\n\n\n\n\n\nciencia\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2017\n\n\n\n\n\n\n  \n\n\n\n\nConstruyendo una Zanfona (parte V)\n\n\n\n\n\n\n\nmusica\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2017\n\n\n\n\n\n\n  \n\n\n\n\nConstruyendo una Zanfona (parte IV)\n\n\n\n\n\n\n\nmusica\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nNov 9, 2017\n\n\n\n\n\n\n  \n\n\n\n\nConstruyendo una Zanfona (parte III)\n\n\n\n\n\n\n\nsin-categoria\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2017\n\n\n\n\n\n\n  \n\n\n\n\nConstruyendo una Zanfona (parte II)\n\n\n\n\n\n\n\nmusica\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2017\n\n\n\n\n\n\n  \n\n\n\n\nOpciones de Open Access “verde” para científicos\n\n\n\n\n\n\n\nciencia\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2017\n\n\n\n\n\n\n  \n\n\n\n\nConstruyendo una Zanfona (parte I)\n\n\n\n\n\n\n\nmusica\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2017\n\n\n\n\n\n\n  \n\n\n\n\nAVATAR #visualMOOC\n\n\n\n\n\n\n\nvisual-thinking\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2017\n\n\n\n\n\n\n  \n\n\n\n\nComienza el MOOC Visual Thinking en educación\n\n\n\n\n\n\n\nvisual-thinking\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2017\n\n\n\n\n\n\n  \n\n\n\n\nHablemos en Japonés - NHK WORLD\n\n\n\n\n\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2016\n\n\n\n\n\n\n  \n\n\n\n\n¿Síntesis de voces cantadas con letra en Linux? Ahora es posible\n\n\n\n\n\n\n\nmusica\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2016\n\n\n\n\n\n\n  \n\n\n\n\nCómo conectar a un kernel remoto de IPython en Spyder\n\n\n\n\n\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2016\n\n\n\n\n\n\n  \n\n\n\n\nUn pensamiento sobre los SVM\n\n\n\n\n\n\n\nciencia\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2016\n\n\n\n\n\n\n  \n\n\n\n\nJesucristo Superstar - Santa Cecilia 2015\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nMigrando todo a GitHub\n\n\n\n\n\n\n\nchusynth\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPensamientos sobre los GMO\n\n\n\n\n\n\n\nciencia\n\n\n\n\n\n\n\n\n\n\n\nSep 2, 2015\n\n\n\n\n\n\n  \n\n\n\n\nFluidSynth superado. Ahora empieza lo bueno.\n\n\n\n\n\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2015\n\n\n\n\n\n\n  \n\n\n\n\nY vuelvo a tocar con Achake\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nJul 15, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAhora empieza lo bueno\n\n\n\n\n\n\n\nciencia\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nJun 11, 2015\n\n\n\n\n\n\n  \n\n\n\n\nChusoCol\n\n\n\n\n\n\n\nmusica\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2015\n\n\n\n\n\n\n  \n\n\n\n\nResultado de la Velada\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2015\n\n\n\n\n\n\n  \n\n\n\n\nXIX Veladas Musicales\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2015\n\n\n\n\n\n\n  \n\n\n\n\nErrare Humanum Est\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2015\n\n\n\n\n\n\n  \n\n\n\n\n¿Qué IDE puedo usar para trabajar con Python como si fuera Matlab?\n\n\n\n\n\n\n\nciencia\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2015\n\n\n\n\n\n\n  \n\n\n\n\nTocando mis primeras notas\n\n\n\n\n\n\n\nmusica\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2015\n\n\n\n\n\n\n  \n\n\n\n\nA estas alturas\n\n\n\n\n\n\n\nchusynth\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2015\n\n\n\n\n\n\n  \n\n\n\n\nMañana me pongo\n\n\n\n\n\n\n\nciencia\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2015\n\n\n\n\n\n\n  \n\n\n\n\nLos proyectos personales\n\n\n\n\n\n\n\nciencia\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2015\n\n\n\n\n\n\n  \n\n\n\n\nEntre APIs y Ces…\n\n\n\n\n\n\n\nchusynth\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2015\n\n\n\n\n\n\n  \n\n\n\n\n¡Comienza la Aventura!\n\n\n\n\n\n\n\nchusynth\n\n\ntecnologia\n\n\n\n\n\n\n\n\n\n\n\nFeb 18, 2015\n\n\n\n\n\n\n  \n\n\n\n\nMonos en el Espacio\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2014\n\n\n\n\n\n\n  \n\n\n\n\nFlor del Cerezo\n\n\n\n\n\n\n\nmusica\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2014\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/2018-12-04-software-carpentry-workshop-en-el-ift-e-icmat-del-csic/index.html",
    "href": "teaching/2018-12-04-software-carpentry-workshop-en-el-ift-e-icmat-del-csic/index.html",
    "title": "Software Carpentry Workshop en el IFT e ICMAT del CSIC",
    "section": "",
    "text": "Ahí estuve como instructor certificado de las Carpentries en el Workshop para la gente del Instituto de Física Teórica (IFT) y el Instituto de Ciencias Matemáticas (ICMAT) del CSIC, en Madrid. Ha sido mi primera experiencia y estoy muy agradecido a los organizadores por contar conmigo. Muchísimas gracias a todos!\n\n\n\n\n\n\n\nEl link al workshop: https://adgdt.github.io/2018-11-28-cftmat/"
  },
  {
    "objectID": "blog/2015-02-18-comienza-la-aventura/index.html",
    "href": "blog/2015-02-18-comienza-la-aventura/index.html",
    "title": "¡Comienza la Aventura!",
    "section": "",
    "text": "Por fin empieza esta aventura: hacer un dispositivo monotarea que se comporte como un sampler basado en SoundFonts, o lo que es lo mismo, mi ChuSynth. Mi plan es utilizar fluidsynth como una librería cargada desde python, utilizando pyFluidSynth (que estoy forkeando para añadir funcionalidades que necesito) desde donde se puedan realizar tareas básicas como cargar soundfonts, cambiar presets, etc, y que de los mensajes midi se ocupe fluidsynth.\n\n\n\nSin nombre\n\n\nLas anteriores pruebas con la Raspberry Pi B+ habían sido un poco fiasco (temas de velocidad de CPU), pero por fin, con la salida de las Raspberry Pi 2 B, todo ha cambiado. He hecho las primeras pruebas de utilizar fluidsynth incluso con soundfonts grandes, y apenas hay problemas de polifonía.\nAsí pues el proyecto (en principio) se dividirá en las siguientes partes:\n\nDotar a pyFluidSynth de las funciones que necesito para implementar la aplicación (interacción con C++ mediante ctypes):\n\nListar y cambiar los presets\nEstablecer opciones límites de polifonía\n\nCrear el resto de programas de python que corresponden con la interfaz con PiFace y la interfaz de usuario.\nMontarlo todo en la Raspberry Pi y optimizar Raspbian para un single-purpose computer."
  },
  {
    "objectID": "blog/2015-02-21-entre-apis-y-ces/index.html",
    "href": "blog/2015-02-21-entre-apis-y-ces/index.html",
    "title": "Entre APIs y Ces…",
    "section": "",
    "text": "Sí, la interfaz pyFluidSynth que estoy forkeando tiene una función principal: interactuar con la API de fluidsynth, que está escrita en C. Eso lleva a algunos problemas, por ejemplo, en el tipo de datos y estructuras que maneja.\nMás o menos podemos decir que la cosa va viento en popa, y he ampliado el número de funciones que la clase Synth posee con muchas de las funciones que provee la API, pero hay cosas con las que he tenido que recurrir a magia negra. Para obtener una lista de todos los instrumentos que posee una función he tenido que crear una interfaz para capturar durante unos momentos la salida del shell. En fluidsynth, hay dos opciones de obtener la lista: construir una serie de estructuras horrendas (con las que interactuar en python se puede convertir en un infierno), o capturar la salida del shell con los comandos inst SF_ID. Así que opté por esta última.\nTras darle muchísimas vueltas, por fin conseguí hacer una clase, que llamé StdoutHandler, y que llamando objeto.freopen() abres un archivo y escribe la salida de la shell en el mismo, y con objeto.freclose() se devuelve la salida al stdout del sistema.\nAsí que esto es lo que he hecho, por si a alguien le hace falta (basado en este post de StackOverflow):\n[code lang=python] class StdoutHandler(object): def __init__(self, f): “““Create new stdouthandler, for management of stdin and stdout (some methods of Synth DO need to capture stdout stream).”“” self.prevOutFd = os.dup(1) self.prevInFd = os.dup(0) self.prevErrFd = os.dup(2) self.newf = open(f, ‘w’) self.newfd = self.newf.fileno() # The new file output\ndef freopen(self): ““” Redirects the standard input, output and error stream to the established newfd. :return: ““” os.dup2(self.newfd, 0) os.dup2(self.newfd, 1) os.dup2(self.newfd, 2)\ndef freclose(self): ““” Closes the modified input, output and error stream :return: ““” self.newf.close() os.dup2(self.prevOutFd, 1) os.close(self.prevOutFd) os.dup2(self.prevInFd, 0) os.close(self.prevInFd) os.dup2(self.prevErrFd,2) os.close(self.prevErrFd) [/code]"
  },
  {
    "objectID": "blog/2015-02-25-los-proyectos-personales/index.html",
    "href": "blog/2015-02-25-los-proyectos-personales/index.html",
    "title": "Los proyectos personales",
    "section": "",
    "text": "Esto es una reflexión un tanto manida, pero de la que uno se da cuenta de vez en cuando. Cuando inicias un proyecto personal, por el mero hecho de hacer algo nuevo por ti mismo, con tus manos, ya sea un armario de Ikea o un theremin casero, no estás perdiendo el tiempo. La gente hablará, dirán que “cuánto tiempo libre tiene ese tío”, aunque seas el más ocupado del mundo. Tú mismo llegarás a creerte que estás perdiendo el tiempo.\nPero no. Un proyecto personal es mucho más que un Hobby. Hobby es ir a comprar los viernes por la tarde a recogidas. Un proyecto personal es la búsqueda de algo que no has podido encontrar, es ese vaivén sentimental que sólo provocan los altibajos de uno de estos proyectos: las horas -y días- de frustración y la increíble realización personal que supone cuando se consigue una de las pequeñas metas que se ponen.\nAl final de un proyecto personal aprendes mucho. Aprendes las tecnologías que utilizas (ya sea que existen diferentes tipos de tornillos o un nuevo lenguaje de programación). Aprendes a enfrentarte a retos, y a no abandonar. Aprendes a superar los obstáculos que pone la vida, algo que, en la sociedad de la obsolescencia programada, no solemos hacer. Nos gusta más el usar y tirar.\nPor último, aprendes a conocerte a tí mismo, cuales son tus capacidades, cuales son tus puntos débiles. Y los potencias y solucionas respectivamente. Al final de un proyecto eres otra persona. Quizá has ganado un armario de Ikea (eso lo puedes comprar), pero lo más importante es que te has ayudado a conocerte, un poquito más, a tí mismo."
  },
  {
    "objectID": "blog/2015-03-03-a-estas-alturas/index.html",
    "href": "blog/2015-03-03-a-estas-alturas/index.html",
    "title": "A estas alturas",
    "section": "",
    "text": "Y cuando ya pensaba que tenía el fork de pyFluidSynth casi terminado, me doy cuenta de que todavía me falta lo más importante: añadir el driver midi. Sin embargo, conforme uno va implementando cosas se da cuenta de que cada vez es más complicado añadir funcionalidad desde python a una API en C.\nEn esta ocasión, utilizando las funciones de la API, logro crear un driver MIDI al que conectar luego un teclado. Pero en cuando mando la primera nota, me manda un bonito SYSSEG: reading NULL VMA que hará las delicias de todos. ¿Por qué tengo un puntero nulo? Creía que ctypes se encargaría de todo.\nEste es el código que manejo ahora mismo:\n[code lang=python] def start_midi(self, mididriver=‘alsa_seq’): ““” Starts the MIDI driver to allow the MIDI keyboard interaction. :param mididriver: name of the midi driver, that can be one of these: ‘alsa_raw’, ‘alsa_seq’, ‘coremidi’, ‘jack’, ‘midishare’, ‘oss’, ‘winmidi’ :return: ““” if mididriver is not None: assert (mididriver in [‘alsa_raw’, ‘alsa_seq’, ‘coremidi’, ‘jack’, ‘midishare’, ‘oss’, ‘winmidi’]) fluid_settings_setstr(self.settings, ‘midi.driver’, mididriver) # Optionally: sets the real time priority to 99. fluid_settings_setnum(self.settings, ‘midi.realtimeprio’, 99) self.midi_driver = new_fluid_midi_driver(self.settings, fluid_midi_router_handle_midi_event, new_fluid_midi_event) return self.midi_driver [/code]\nNo tengo ni idea de como voy a salir del paso, porque en principio parece que la función fluid_midi_router_handle_midi_event debería pasar todos los comandos de entrada al sintetizador, pero en lugar de ello, da fallo de segmentación. No sé si es por el midi.realtimeprio (que siempre da un warning), o por la función en sí, o por el recientemente añadido new_fluid_midi_event, pero la verdad es que estoy bastante estancado. A ver si esta tarde salimos del paso."
  },
  {
    "objectID": "blog/2015-03-03-manana-me-pongo/index.html",
    "href": "blog/2015-03-03-manana-me-pongo/index.html",
    "title": "Mañana me pongo",
    "section": "",
    "text": "Pero de verdad. Mañana empiezo el curso de Edx llamado 6.00.2x Introduction to Computational Thinking and Data Science. Otro MOOC más que espero que me de buenas bases para migrar decididamente desde el malvado y pesado, pero cómodo, Matlab a Python, que es Open Source (vaya, de lo mío).\nEs un paso importante, porque además de seguir a la peña científica que generalmente están migrando a Python desde plataformas como R o Matlab con proyectos como SciPy, apoyo a proyectos que me resultan extremadamente atractivos, como Jupyter, una especie de IPython evolucionado para ser language-agnostic y poder trabajar a la vez con Python, R, y Julia.\nEl mundo del software evoluciona muy rápidamente, y si hasta ahora Matlab tenía el beneficio de la comodidad, multitud de extensiones y paquetes para trabajar en casi cualquier cosa, parece que cada vez Python se yergue como un potente rival. Una listilla con mis razones para hacer el cambio podría ser esta:\n\n\n\n\nMatlab\nPython\n\n\n\n\nLibrerías third-party\nSí\nSí\n\n\nDiseño de Aplicaciones\nHorrendo1\nFácil\n\n\nMulti-purpose\nNo\nSí\n\n\nGráficos\nPropia2\nMatPlotLib\n\n\nOpen Source\nNo\nSí\n\n\nEficiencia Computacional\nBaja\nBaja\n\n\nIntegración con otros lenguajes\nDifícil3\nBuena\n\n\nShell interactivo\nSí\nIPython\n\n\nMultitud de IDEs\nNo\nSí\n\n\n\n\n\nMatlab contiene utilidades para crear interfaces gráficas y programas empaquetados, pero su uso es muy difícil, ineficiente y depende de una instalación de Matlab en el ordenador en el que se ejecute. ↩︎\nLa librería de plots de Matlab es muy variada y los resultados son bastante visuales, pero ha sido superada por ggplot2 y matplotlib hace tiempo. ↩︎\nExisten formas de interactuar con C, C++ y Java desde Matlab, pero de forma un poco limitada. La capacidad de extensión de Python con otros lenguajes lo supera con diferencia. ↩︎"
  },
  {
    "objectID": "blog/2015-03-04-tocando-mis-primeras-notas/index.html",
    "href": "blog/2015-03-04-tocando-mis-primeras-notas/index.html",
    "title": "Tocando mis primeras notas",
    "section": "",
    "text": "Por primera vez, he logrado lanzar fluidsynth desde una terminal python, crear su correspondiente driver MIDI y tocar algunas notas con el teclado en directo. A partir de aquí, es todo mejorar.\nhttps://www.youtube.com/watch?v=2ZC4UAiKpMU\nEl problema que estaba teniendo era con la función new_fluid_midi_driver(settings, handler, event_handler_data), en el que en la documentación aparece como que hay que llamarlo (en C) de esta forma:\n[code lang=C] fluid_settings_t* settings; fluid_midi_driver_t* mdriver; settings = new_fluid_settings(); mdriver = new_fluid_midi_driver(settings, handle_midi_event, NULL); [/code]\nsugiriendo el uso de fluid_midi_router_handle_midi_event() como handler callback. Finalmente, la mejor opción para mi fue:\n[code lang=C] mdriver = new_fluid_midi_driver(settings, fluid_synth_handle_midi_event, synth) [/code]\nO sea, que había que la función fluid_synth_handle_midi_event es la pancea y en ningún sitio de la documentación de API te la especifican. Bien por fluidsynth. Y usar el propio objeto sintetizador synth como event_handler_data."
  },
  {
    "objectID": "blog/2015-03-05-que-ide-puedo-usar-para-trabajar-con-python-como-si-fuera-matlab/index.html",
    "href": "blog/2015-03-05-que-ide-puedo-usar-para-trabajar-con-python-como-si-fuera-matlab/index.html",
    "title": "¿Qué IDE puedo usar para trabajar con Python como si fuera Matlab?",
    "section": "",
    "text": "Esta es la primera pregunta que me hice a la hora de pasarme a Python. Y no es una respuesta fácil. Si dejamos de lado diferencias tan sustanciales como que Python es orientado a objetos y Matlab no, y las diferencias a la hora de trabajar con uno y otro, habría que atender a varias circunstancias. Para mi, un IDE que funcione bien tiene que tener al menos:\n\nEditor integrado (si puede ser con sugerencias)\nVentana de comandos (IPython a ser posible)\nVisor de variables\nPosibilidad de salvar un workspace\n\nPrácticamente todos los IDEs cumplen estas características. Después de mucho navegar por la web me encontré los más parecidos a Matlab que me podía tirar a la cabeza: Spyder y IEP. Ambos cumplen exactamente lo que prometen: un IDE para trabajar con SciPy (con todo lo que ello conlleva: numpy, matplotlib, scipy, sklearn).\n\n\n\nSpyder UI\n\n\nEl primero que probé era Spyder, bastante consolidado ya en el mundillo, y que cumple todo lo anteriormente dicho. Es bueno, fiable y permite guardar el workspace en un único fichero (pero esto también puede ser un problema, porque es un fichero propio de spyder). Tiene un autodetector de las funciones que se están usando, que muestra la ayuda de dicha función en una pestaña (si la tenemos visible). En su contra diré que es más bien feo (tanto la UI como el icono) y que no tiene sugerencias instantáneas.\n\n\n\nEIP UI\n\n\nPor otra parte, conocí EIP, que por el momento me gusta más. Está en un desarrollo un poco más activo, aunque menos maduro que Spyder, con todo lo que ello conlleva. La principal diferencia es que no tiene un asistente para guardar workspace (se puede hacer desde código), pero en contrapartida posee sugerencias live de funciones, objetos y demás que estén en el workspace, lo que es muy conveniente cuando uno está empezando. También en el apartado estético gana por su limpieza e integración con el sistema operativo. Todavía es pronto para hacer un diagnóstico y me quedan muchas horas que trabajar con alguno de ellos, pero por lo pronto, yo me quedo con EIP, por las sugerencias y por su interfaz más pulida. Quizá en algún momento necesite guardar variables del workspace, en ese momento me plantearé que opción es más buena.\nEditado: Una tercera opción que se me olvidó citar al ser de pago (aunque tienen una versión gratuita) es Canopy. Quizá es la que más se parezca a Matlab y viene perfecamente equipado con todo lo necesario para trabajar. Lo que es más, está disponible tanto para Windows como para Mac y Linux, lo que lo hace una opción muy buena a tener en cuenta si no importa el hecho de que no sea open source."
  },
  {
    "objectID": "blog/2015-04-07-errare-humanum-est/index.html",
    "href": "blog/2015-04-07-errare-humanum-est/index.html",
    "title": "Errare Humanum Est",
    "section": "",
    "text": "Errar es humano. O mejor aún, es errar lo que nos hace humanos. Toda una amalgama de errores que se concatenan, y que inundan cada rincón de nuestra vida: desde olvidar donde pone uno las llaves hasta fallos de ejecución en una obra musical, pasando por sesgos cognitivos e incoherencias internas que son las que nos dan poco a poco la vidilla, y la razón para pensar.\nPero es de los fallos en la música de lo que hablaré. Porque si hay algo que me fascinó cuando era mucho más pequeñajo era la perfección de un disco, con una filosofía que bebía directamente del mundo de las ideas de Platón, haciendo de una pista grabada el ideal de la canción que luego cambiaría en cada una de las ejecuciones.\nLa música grabada, en ese momento, me parecía la obra culmen de la música, el pico de perfección que jamás se podría alcanzar, tal vez solo llegar infinitesimalmente cerca. Una suerte de mundo de ideas de platón que, al pasar por nuestras manos, se convertirían al mundo de lo físico añadiendo imperfecciones.\nCon la llegada de la música electrónica llegó una autoimposición bestial de la perfección. Todo se podía racionalizar, cuantizar… La era del MIDI y la informática que transformó a la música en algo inmutable, reproducible. En definitiva, tan inerte como una piedra. Esto está tan dentro de nuestro ADN que nos hace parir chistes tan geniales como:\n\n- ¿Te vienes a echar unas cervezas?\n- No, estoy grabando a un grupo…\n- ¿Grabar? ¿Y eso qué es?\n- Es como el MIDI, pero con personas..\n\nNo es tan alocado como puede parecer, en todo caso. Poco a poco, y estando ya en Anima Adversa, vi como todos nos dejábamos llevar por la obsesión con esa perfección. Una perfección que es falsa.\nRecuerdo habiendo sacado El Grito en el Cielo, como Juanpy dijera: a mi me gusta más El Otro Yo, tiene un alma, un algo. En ese momento, mi respuesta fue: claro, tiene que está mal grabado. Y es increíble como, estando tan acertado, estaba tan equivocado. Por supuesto, el disco es en sí una sucesión de ejemplos de como no hay que grabar. Sin embargo, esa sucesión de imperfecciones hacían que la música cobrase vida.\nHoy en día creo firmemente en que la música sólo está viva en directo, y que por tanto, la música grabada no debe ser reflejo de la perfección inerte del mundo de las ideas. Este mundo de las ideas no existe mas que en nuestras cabezas. La música grabada debe ser una de las reflexiones físicas de nuestro mundo de las ideas interior, y que fluye a través de nuestras propias capacidades de ejecución, entrenadas al máximo.\nY es que errar no es más que el acto creador que nos convierte en dioses capaces de conferir alma a la música. El resto, son piedras."
  },
  {
    "objectID": "blog/2015-05-05-xix-veladas-musicales/index.html",
    "href": "blog/2015-05-05-xix-veladas-musicales/index.html",
    "title": "XIX Veladas Musicales",
    "section": "",
    "text": "xIX Veladas Musicales de la ETSIIT\n\n\nEstán siendo unas semanas muy intensivas de trabajo, pero siempre hay rato para la música. Particularmente, en este caso, nuestro estreno (de moza y mío) como pareja en los escenarios: Acoplados (a couple), en las XIX Veladas Musicales de la ETSIIT.\nEstaremos este Martes 5 de Mayo a partir de las 19:30 en el Salón de Actos. ¡Esperemos que salga muy bien!"
  },
  {
    "objectID": "blog/2015-05-12-resultado-de-la-velada/index.html",
    "href": "blog/2015-05-12-resultado-de-la-velada/index.html",
    "title": "Resultado de la Velada",
    "section": "",
    "text": "Interpretamos una canción, y perpetramos otra. Lo que se dice un completo.\nAquí está Over the Rainbow, de la película El Mago de Oz. https://youtu.be/pS37vlfFx6c\nY luego, Remedios de la Abuela, de los Gandules, en una versión adaptada a la facultad de informática y telecomunicaciones. https://www.youtube.com/watch?v=jhmojh19CPQ"
  },
  {
    "objectID": "blog/2015-05-19-chusocol/index.html",
    "href": "blog/2015-05-19-chusocol/index.html",
    "title": "ChusoCol",
    "section": "",
    "text": "Conforme pasa el tiempo, parece que he abandonado por completo el proyecto ChuSynth. Nada más lejos de la realidad. Simplemente, con diferentes tareas que surgen de la investigación (y ahora también obligaciones docentes) pues no tengo tanto tiempo para dedicar a ello. Sin embargo, en estos días atrás estoy continuando otro proyecto que va de la mano de ChuSynth, y que es su principal fuente de sonido: ChusoCol, una soundfont ligera (alrededor de 300 MB), enfocada en el realismo de instrumentos acústicos y que pueda ser ejecutada de forma eficiente en una Raspberry Pi.\n\n\n\nChusoCol\n\n\nLa página web la diseñé hace tiempo y la mayor parte del trabajo de actualización lo hice durante mi estancia en Cambridge, pero ahora estoy dando los últimos retoques y espero poder lanzar ChusoCol 2 en poco tiempo. Mientras tanto, en la página web se puede descargar la primera ChusoCol, que me acompañó a muchísimos sitios cuando iba de conciertos con Anima Adversa."
  },
  {
    "objectID": "blog/2015-06-11-ahora-empieza-lo-bueno/index.html",
    "href": "blog/2015-06-11-ahora-empieza-lo-bueno/index.html",
    "title": "Ahora empieza lo bueno",
    "section": "",
    "text": "Así que tras la vuelta de esas vacaciones-trabajo llamadas congresos, nos toca ponernos a trabajar. Nos han seleccionado Tres papers para un Special Issue de impacto 6!! Pero hay que hacer el trabajo desde cero.\nTambién llega la época de corregir, revisar papers, etc, así que manos a la obra.\nMientras tanto, ha llegado por fin la grabación de nuestra maravillosa actuación en la 9ª de Beethoven: https://youtu.be/Ua-1Fm7ATFE?t=6m40s"
  },
  {
    "objectID": "blog/2015-07-15-y-vuelvo-a-tocar-con-achake/index.html",
    "href": "blog/2015-07-15-y-vuelvo-a-tocar-con-achake/index.html",
    "title": "Y vuelvo a tocar con Achake",
    "section": "",
    "text": "Lo cual es un honor enorme. El grupo de Rock Urbano por excelencia de mi pueblín, Achake cumple 10 años y lo van a celebrar por todo lo alto con un concierto en el paseo. Además, el día 13 de Agosto, mi cumpleaños.\nEs un buen regalo volver a compartir escenario con estos fieras a los que he visto nacer, crecer y hacerse grandes desde que yo mismo era un moco. Han sido probablemente el grupo exponente de Alcalá, y una de las bazas más importantes de la música del pueblo, si no la que más (por supuesto, obviando a superstar como Roko, y a los grandes Flash allá por su época dorada).\nYa toque con ellos una vez, y también grabando disco. Esta noche repetirán, y será un espectáculo para recordar. Espero que salga, por lo menos, como el X aniversario de Anima Adversa, casi el último concierto en el que estuve, y un bombazo.\nMientras, os dejo con la presentación:\nhttps://www.youtube.com/watch?v=EvN48xDXidU"
  },
  {
    "objectID": "blog/2015-08-26-fluidsynth-superado-ahora-empieza-lo-bueno/index.html",
    "href": "blog/2015-08-26-fluidsynth-superado-ahora-empieza-lo-bueno/index.html",
    "title": "FluidSynth superado. Ahora empieza lo bueno.",
    "section": "",
    "text": "Por fin puedo decir que he echado un pulso a fluidsynth, sus python bindings (pyFluidSynth, see original project and my personal fork) y a todas las dificultades que un proyecto de estas características te pone delante. Pero lo primero es lo primero, así que aquí tenéis una Demo de como funciona fluidsynth en una Raspberry Pi 2 B+ (Raspbian), haciendo llamadas mediante los python bindings de fluidsynth:\nhttps://www.youtube.com/watch?v=DEsfSsX-g4g\nY ahora vamos con los detalles. El video muestra simplemente una llamada a liveDemo.py, un script que he preparado para probar 20 segundos del programa 0 y 20 segundos del programa 50 de cualquier soundfont que tengamos (por defecto carga /usr/share/sounds/sf2/FluidR3_GM). Así que los pasos para probarlo, desde una Raspberry Pi conectada a internet con Raspbian son los siguientes.\nEn primer lugar, nos aseguramos de tener instalado FluidR3_GM y las librerías de python de ALSA:\nsudo apt-get install fluid-soundfont-gm python-pyalsa\nPosteriormente, hacemos un clone de pyFluidSynth, con el código:\ngit clone https://github.com/pakitochus/pyfluidsynth.git\nNavegamos hasta el lugar donde está la instalación y ejecutamos:\ncd pyfluidsynth sudo python setup.py install\nY en principio, ya podríamos ejecutar el test con:\ncd test python liveDemo.py\nPor supuesto, hace falta tener un teclado midi conectado a la raspberry, yo sugiero MIDI USB. En el script, se presupone que el puerto en el que está conectado es el 20,0, pero esto no tiene por qué ser así. La forma correcta de saber cual es el dispositivo que tenemos completado es mediante el comando:\naconnect -i\nque listará algo así como:\n[code lang=text] cliente 0: ‘System’ [tipo=kernel] 0 ‘Timer’ 1 ‘Announce’ cliente 14: ‘Midi Through’ [tipo=kernel] 0 ‘Midi Through Port-0’ cliente 23: ‘MIDI KEYBOARD’ [tipo=kernel] 0 ‘MIDI KEYBOARD MIDI 1’ [/code]\nSuponiendo esos datos, para cambiar el que está por defecto, editamos el archivo liveDemo.py, y en la línea 29, donde aparece\n[code lang=text] sender = (20, 0) # Modify according to the current port of the USB MIDI input [/code]\ncambiamos por\n[code lang=text] sender = (29, 0) [/code]\nDe igual modo, para cambiar la soundfont a utilizar o modificar la ruta, vamos a la línea 22 del archivo, y sustituimos la línea\n[code lang=text] sfid = fs.sfload(“/usr/share/sounds/sf2/FluidR3_GM.sf2”) [/code]\npor la ruta hasta el archivo de soundfont que queramos. En el video, he utilizado una colección que he recopilado y creado -a partes iguales- llamada ChusoCol, que podéis encontrar en Sourceforge (pronto subiré la ChusoCol 2, la del video).\nY eso es todo. No deja de ser una demostración de como funciona el fork de pyFluidSynth. Ahora es cuando viene lo bueno: convertir la RPi2 en un single-purpose computer y añadir todos los controles para usar el PiFace Control and Display module.\nEsto no ha hecho más que empezar. Pero ya hay un paso menos que dar."
  },
  {
    "objectID": "blog/2015-09-02-pensamientos-sobre-los-gmo/index.html",
    "href": "blog/2015-09-02-pensamientos-sobre-los-gmo/index.html",
    "title": "Pensamientos sobre los GMO",
    "section": "",
    "text": "Los Organismos Genéticamete Modificados (GMO por su siglas en inglés) son organismos a los cuales se les ha introducido parte de un genoma diferente al de su especie original. Normalmente se les conoce como transgénicos, esto es, que poseen genes de otras especies.\nMucho se ha hablado de Monsanto, y hoy en día, debido a falta de argumentos en torno a la seguridad de los GMO, la política de críticas a los GMO se centra en atacar a esta empresa y sus prácticas comerciales. Ahí no me meto, porque tienen para darles por delante y por detrás.\nPero por donde quiero ir, por donde va mi reflexión, es por la idoneidad de utilizar un proceso tecnológicamente avanzado para editar el genoma de una especie y modificar las características que queramos. No es nuevo, y sale frecuentemente a relucir, que todos los alimentos que consumimos, TODOS, son GMO. Durante siglos, milenios, se han seleccionado las semillas que daban tomates más gordos, árboles con más peras y vacas que daban más leche.\nLa vaca y toro vienen del Uro, su equivalente salvaje, gracias a la modificación genética. El perro, del lobo. Los cerdos de los jabalís (aun siendo técnicamente la misma especie). Lo mismo con la fruta y vedura, hasta llegar a saber que la naranja proviene de un cruce de la mandarina y el pomelo. Todos han sido artificialmente seleccionados y cruzados para conseguir el producto que ahora nos gusta.\nPor lo que la pregunta no es si los GMO son buenos o malos. Es tarde para ello, llevamos toda la vida consumiéndolos. La cuestión es: ¿qué es mejor, un organismo al que se le han modifcado solamente las características deseadas o un organismo cruzado que almacena mutaciones unas detrás de otras sin ningún control? Porque eso, amigo, son los tomates que te estás comiendo.\nY para terminar, un poco de luz sobre las razas de los perros, y los peligros de la selección artficial: https://www.youtube.com/watch?v=S5aJ9R6wUn4"
  },
  {
    "objectID": "blog/2015-11-10-migrando-todo-a-github/index.html",
    "href": "blog/2015-11-10-migrando-todo-a-github/index.html",
    "title": "Migrando todo a GitHub",
    "section": "",
    "text": "Sourceforge está que arde. O estaba. Cada vez se parece más a un erial, y muchos de los proyectos que le daban su “vidilla” están ya desapareciendo. Por ejemplo, hace dos años que GIMP decidió dejar Sourceforge por su política de introducir adware, y aún así el escándalo se ha repetido este año. Aunque han dado marcha atrás -sólo para este caso en concreto-, Sourceforge parece abocada al fracaso.\nPara no hundirme con el barco, al que ya me subí tarde, y debido a mi cada vez más contínuo uso de github en proyectos personales, voy migrar lo último que me quedaba en SF: ChusoCol. He abierto ya mi repositorio y creado una release con la versión v1.0.0 de la colección, aunque espero actualizarlo pronto. Espero que esté a tiempo para cuando tengamos ChuSynth preparado.\nQuede así por mi parte abandonada la anterior página -aún me estoy planteando dejarla como mirror-, y pasamos a centralizar todo en Github. Que funciona."
  },
  {
    "objectID": "blog/2015-12-01-jesucristo-superstar-santa-cecilia-2015/index.html",
    "href": "blog/2015-12-01-jesucristo-superstar-santa-cecilia-2015/index.html",
    "title": "Jesucristo Superstar - Santa Cecilia 2015",
    "section": "",
    "text": "https://www.youtube.com/playlist?list=PL71zZgXa3aTxJqQyl3tyWrZjRhLs3s11_\nHa sido un fin de semana de vértigo. Quizá ahora, cuando ya las aguas vuelven a su cauce, hay más tiempo para la reflexión. Siempre he pensado que la música une a las personas como ninguna otra cosa puede. Quizá es porque la música toca al ser humano en muchos niveles, que van desde lo consciente hasta el alma misma. Quizá porque en un escenario, aunque interpretes un papel, estás desnudo, junto a una panda de locos que también desnudan su alma, y que entregan lo mejor de si mismos a una audiencia que va a aprender más de tí que cualquier red social (a ver si superas eso, Google).\nMuchos saben lo importante que era para mi este musical (y este pequeño psicópata-humorista llamado Herodes) antes siquiera de saber de este proyecto. Y cómo el día en que Inma habló con Jorge Molina y Laura yo ya sabía que esto no podía ser otra cosa que una hermosísima experiencia vital. Muchos ensayos con gente conocida, como Juanra, Koke, Melanie, María Isabel o Javi Alba y por conocer, como Chechu, Marta, Merce, Manuel, Lucía, Lope, Sole o Jorge Sánchez y que al final parecemos una gran familia. Y grandes músicos venidos del pueblo (Tingui, Mario, Juanpa, David) o de fuera (Javi, Paco) que han puesto banda sonora a nuestras vidas. Y las currantes más grandes sin las que esto no hubiese sido posible, Lucía y Marta. Y dos figurantes de lujo, y grandes amigos: Jesús y Paco. Y toda la AM Pep Ventura.\nYa han pasado los nervios, ya ha pasado la resaca musical. Quede en el recuerdo del pueblo una de las cosas más grandes que se han hecho. En el mío, lo musical ha dejado huella. Pero lo humano ha superado todo, desbordándome por todas las dimensiones que algún astrofísico se invente para explicar el universo. El mayor consuelo de que se haya acabado, es que esto sigue. Que nos veremos más veces, si Dios quiere, para seguir volcando almas en el contenedor de la música. Gracias por todos los que han hecho esto posible. Gracias a vosotros.\nQué cortos se me han hecho estos meses…"
  },
  {
    "objectID": "blog/2016-01-22-un-pensamiento-sobre-los-svm/index.html",
    "href": "blog/2016-01-22-un-pensamiento-sobre-los-svm/index.html",
    "title": "Un pensamiento sobre los SVM",
    "section": "",
    "text": "Estaba leyendo los increíbles post de Cristopher Olah, in Colah’s Blog para aprender sobre visualización de datos en espacios altamente dimensionales, y como nota al pie en una de las afirmaciones me encuentro esto:\n\nPeople sometimes complain: “Neural networks are so hard to understand! Why can’t we use understandable models, like SVMs?” Well, you understand SVMs, and you don’t understand visual pattern recognition. If SVMs could solve visual pattern recognition, you would understand it. Therefore, SVMs are not capable of this, nor is any other model you can really understand. (I don’t mean this to be a ‘proof’ obviously, but I am pretty serious about this view.)\n\nHe oído ese argumento respecto a SVM muchísimas veces, y la verdad nunca se me había ocurrido planteármelo. Siempre lo tomé como cierto, puesto que tiene bastante lógica (es mejor usar algo que se puede comprender), pero… también es cierto lo que dice acerca de que entiendas o no reconocimiento de patrones.\nQuizá haya que repensar algo, quizá es hora de aprender más… de darle una oportunidad a las redes neuronales. Y quizá es el mejor momento. Toca aprender, pues."
  },
  {
    "objectID": "blog/2016-04-12-como-conectar-a-un-kernel-remoto-de-ipython-en-spyder/index.html",
    "href": "blog/2016-04-12-como-conectar-a-un-kernel-remoto-de-ipython-en-spyder/index.html",
    "title": "Cómo conectar a un kernel remoto de IPython en Spyder",
    "section": "",
    "text": "Bueno, pues hoy os voy a contar como utilizar Spyder para conectarse a un kernel remoto de IPython, por ejemplo, para realizar tareas que requieran una gran cantidad de RAM o de tiempo de procesamiento en un servidor. El proceso consta básicamente de dos pasos: lanzar el kernel en el servidor y conectarse a él desde Spyder.\n\nLanzar un kernel en el servidor\nPara lanzar el kernel en el servidor, el proceso dependerá de cómo estemos habituados a realizar la conexión. Normalmente yo recomiendo utilizar `ssh` para la conexión por su seguridad y porque es la que utiliza el propio Spyder. En cualquier caso, utilizando ssh, la conexión se realizaría:\nssh usuario@servidor\nTras conectar al servidor, lanzamos un kernel de IPython (para ello debemos tener instalado Python e IPython en el servidor) con el comando:\nipython kernel\nTras lanzar el kernel nos aparece un texto parecido a esto:\n\n\n\nProceso lanzando el kernel\n\n\nEs importante el último número que nos aparece, en nuestro caso kernel-17478.json. Este será el archivo que vamos a utilizar para conectarnos al kernel desde Spyder. Hay que puntualizar que una vez que nos conectemos a este kernel solo podremos acceder a los datos de la máquina en la que se está ejecutando el kernel, y no de nuestra máquina local.\n\n\nConectarse a un kernel existente desde Spyder\nPara conectarse al kernel existente, debemos descargarnos el archivo kernel-17478.json que hemos descrito anteriormente. En una instalación linux Ubuntu, ésta se suele encontrar en la carpeta /home/mi_usuario/.local/share/jupyter/runtime (en caso del IPython 4.0). Esta ruta puede variar según la versión del sistema operativo, python e IPython, por lo que es recomendable comprobarlo con anterioridad.\nEDIT: si no se localiza, se puede acceder a la ruta donde están los kernel mediante el comando:\njupyter –runtime-dir\nUna vez que estemos en esa carpeta y nos hayamos descargado el archivo kernel-xxx.json, lo copiamos en un directorio de nuestra máquina local y abrimos  Spyder.\n\n\n\nSpyder Interface\n\n\nEncima de la ventana de la terminal de IPython, justo en la esquina superior derecha, aparece una pestaña desplegable. Abrimos y pulsamos “Conectarse a un núcleo existente”. Esto abre una ventana emergente, que será similar a esta:\n\n\n\nVentana emergente\n\n\nUna vez allí, seleccionamos el archivo .json que hemos descargado al principio y rellenamos nuestros datos de conexión (usuario@servidor, contraseña), y al pulsar Aceptar ya nos habremos conectado al kernel remoto.\nEs importante notar que el kernel no se puede cerrar desde la terminal SSH, sino que debemos hacerlo desde nuestra máquina local. Para terminar la ejecución del kernel, escribimos en la terminal de Ipython:\nexit()\nY así se cierra del todo."
  },
  {
    "objectID": "blog/2016-08-06-sintesis-de-voces-cantadas-con-letra-en-linux-ahora-es-posible/index.html",
    "href": "blog/2016-08-06-sintesis-de-voces-cantadas-con-letra-en-linux-ahora-es-posible/index.html",
    "title": "¿Síntesis de voces cantadas con letra en Linux? Ahora es posible",
    "section": "",
    "text": "Sí, es algo que me ha traído por el camino de la amargura durante mucho tiempo, debido a mi extraña afición a cantar, arreglos corales y a la necesidad de muchas personas de una guía sonora para aprenderse las canciones.\nNo todo el mundo sabe leer partituras, y en los coros amateurs, los midis o audios con las diferentes voces son una parte fundamental de la dinámica. En este marco, normalmente son partes sin letra, en la que uno tiene que guiarse por la partitura e intentar ir siguiendo las sílabas con respecto a la música que va sonando en estas guías de audio. Es fácil intuir el avance fundamental: un sintentizador vocal que fuera capaz de cantar las letras.\nMuchas tecnologías de cantantes virtuales han aparecido en los últimos años, siendo las más conocidas el Yamaha Vocaloid o East West Symphonic Choirs. Con estos paquetes se puede conseguir un resultado bastante profesional que incluso puede servirnos para decorar con coros algunas piezas musicales de estudio, cuando no hay disponibilidad. En el caso de Vocaloid, existen incluso discos cantados por cada una de las diferentes “voces” que poseen, todo en la meca de la tecnología: Japón. Sin embargo, estos paquetes son muy pesados para la aplicación que se busca en coros amateur, y normalmente requieren del procesamiento en un DAW para obtener un resultado aceptable. Y lo que es más, son incapaces de leer partituras.\nEn este ámbito surgen las soluciones de MYRIAD, que integra un editor de partituras (bastante obsoleto ya), al que se le puede añadir VirtualSinger, una suerte de Loquendo capaz de entonar. Esta es la primera opción para muchos, y que funciona razonablemente bien, aunque dando resultados que no son realistas en absoluto (tampoco lo requieren).\nPor todo ello, y con la idea de utilizar Software Libre, os presento mi último descubrimiento: Sinsy. Se trata de una iniciativa abierta japonesa, que es capaz de leer partituras directamente del estándar MusicXML (el que podéis exportar desde cualquier paquete, por ejemplo, MuseScore). Funciona bastante bien, con resultados más realistas que virtualsinger, y siendo gratis y abierto. La única pega que tiene es que solo soporta dos lenguajes (por ahora): japonés e inglés.\nPor ahora, Sinsy se ha incoporado a mi flujo de trabajo con partituras y así quedará por bastante tiempo, hasta que aparezca otra tecnología que cubra ese vacío en Linux. Por lo pronto, es la única y la más razonable. Espero que os sirva tanto como a mi."
  },
  {
    "objectID": "blog/2016-09-12-hablemos-en-japones-nhk-world/index.html",
    "href": "blog/2016-09-12-hablemos-en-japones-nhk-world/index.html",
    "title": "Hablemos en Japonés - NHK WORLD",
    "section": "",
    "text": "El título de esta entrada es también el título de un curso de Japonés para españoles ofrecido por la NHK World (la radio pública japonesa). Estos días, con motivo de mi viaje próximo a Japón, tenía intención de escuchar algo para ir haciendo oído. Sin embargo, me topé con que el feed RSS de la página oficial no listaba mas que el último capítulo, de los 48. De modo que ni corto ni perezoso me puse manos a la obra para intentar crear un feed que contuviera todos los episodios usando web scraping.\nTras muchas vueltas, di con un plugin para Chrome (y por ende, para Opera), llamado Scraper, que te permite hacer web scrapping y exportar a una hoja de cálculo. Tras ello, di con varios problemas, entre ellos mi carencia en expresiones regulares (lo sé, soy un desastre para eso xD), y finalmente con un producto final, alojado en esta web, que sin embargo, siendo correctamente validado, seguía sin listar los episodios en mi querido Podkicker. De modo que al final opté por la linea recta, y lo alojé en feedburner, con lo que finalmente tengo acceso a todos los capítulos.\nAquí el enlace, para quien le pueda servir:\nhttp://feeds.feedburner.com/hablemosJapones\nEspero que os sirva. Un saludo!"
  },
  {
    "objectID": "blog/2017-05-03-avatar-visualmooc/index.html",
    "href": "blog/2017-05-03-avatar-visualmooc/index.html",
    "title": "AVATAR #visualMOOC",
    "section": "",
    "text": "Yo soy Francisco Jesús Martínez Murcia, y estas son las vistas exterior e interior de mi cabeza. Usaré la resonancia magnética como avatar porque define perfectamente mi principal interés: el cerebro, y el material con el que trabajo: imágenes médicas.\nSoy estudiante de doctorado en la Universidad de Granada, y con la tesis estoy ya en capilla."
  },
  {
    "objectID": "blog/2017-05-03-comienza-el-mooc-visual-thinking-en-educacion/index.html",
    "href": "blog/2017-05-03-comienza-el-mooc-visual-thinking-en-educacion/index.html",
    "title": "Comienza el MOOC Visual Thinking en educación",
    "section": "",
    "text": "Vamos a ver qué aprendemos y si hay tiempo para hacerlo todo, con tanta cosa de por medio."
  },
  {
    "objectID": "blog/2017-11-02-construyendo-una-zanfona-gracias-a-ugears/index.html",
    "href": "blog/2017-11-02-construyendo-una-zanfona-gracias-a-ugears/index.html",
    "title": "Construyendo una Zanfona (parte I)",
    "section": "",
    "text": "Siempre me han fascinado los instrumentos musicales, especialmente los que se usaban en música antigua como el dulcimer, el arpa o la zanfona. Por eso mi alegría fue máxima al encontrar una campaña muy prometedora en kickstarter: UGEARS Hurdy Gurdy, que prometía enviar unos recortables en madera para poder construir una Zanfona (Hurdy Gurdy en inglés).\nPor fin me ha llegado el material a casa, y planeo ponerme a mover cielo y tierra para poder terminarla y empezar a hacer cosas que suenen viejunas, como a mi me encanta. Por lo pronto he empezado por la rueda, parte fundamental. Ya iré posteando los avances por aquí."
  },
  {
    "objectID": "blog/2017-11-06-opciones-de-open-access-verde-para-cientificos/index.html",
    "href": "blog/2017-11-06-opciones-de-open-access-verde-para-cientificos/index.html",
    "title": "Opciones de Open Access “verde” para científicos",
    "section": "",
    "text": "Es interesante como a menudo se desconocen las opciones del llamado green open access a la hora de publicar investigación en Internet. Esto se debe, en parte, al interés por fomentar el gold open access (también llamado paid open access), que es aquel por el que las editoriales cobran entre cientos y miles de euros para licenciar el trabajo de los científicos como acceso abierto.\n\nSin embargo, para la Unión Europea, y en general para el mundo científico, acceso abierto significa poder acceder a la investigación que se está haciendo, y eso incluye poder subir copias personales de la investigación que se realiza. Gracias a una charla de Nicolás Robinson el viernes pasado, todo me quedó mucho más claro, así que lo pongo por aquí para que no se me olvide a mi, y para todo aquél que le pueda servir de algo. Las licencias editoriales y lo que se puede subir depende de la versión del archivo, que incluyen: pre-print, post-print, y published. En breve:\n\npre-print es la versión que se envía a la revista la primera vez. No tiene contribución alguna de revisores ni editores, y por tanto su publicación es siempre posible.\npost-print es la versión post-revision, en ella se considera que ya hay contribución de la editorial, en cuanto a las modificaciones debidas al proceso de revisión. Según la revista puede variar: en algunas es posible publicarlo directamente, en otras existe un embargo (tiene que pasar un cierto tiempo antes de poder publicarlo), y en otras no se puede publicar. Se pueden consultar en la lista Sherpa-Romeo.\npublished es la versión final publicada por la revista. En gold open access depende de la licencia (generalmente CC BY)  se puede publicar donde se quiera, pero hay que consultar Romeo.\n\nY la pregunta del millón: ¿dónde subo mi material? Existen infinidad de repositorios (opciones de hospedaje) indexados por diferentes buscadores, aunque Google Scholar suele buscar en casi todos ellos. Mucha gente suele subir su investigación a ResearchGate, aunque existe actualmente una tensión con las editoriales que amenaza con eliminar gran parte del material allí alojado.  Otros repositorios muy populares incluyen ArXiv (nacido de la Física) o Zenodo (de la Unión Europea), en los que también se puede alojar material suplementario e incluso, en el caso de Zenodo, generar DOIs para piezas de software y versiones. A nivel institucional, en la UGR tenemos Digibug, aunque es una opción poco amigable a mi parecer.\nEn fin, no hay excusa para no subir a la red versiones de nuestros trabajos, aunque sean las preliminares."
  },
  {
    "objectID": "blog/2017-11-07-construyendo-una-zanfona-parte-ii/index.html",
    "href": "blog/2017-11-07-construyendo-una-zanfona-parte-ii/index.html",
    "title": "Construyendo una Zanfona (parte II)",
    "section": "",
    "text": "Preparando la caja y el mecanismo de la rueda.\n[gallery ids=“660,659,658,657”]"
  },
  {
    "objectID": "blog/2017-11-08-construyendo-una-zanfona-parte-iii/index.html",
    "href": "blog/2017-11-08-construyendo-una-zanfona-parte-iii/index.html",
    "title": "Construyendo una Zanfona (parte III)",
    "section": "",
    "text": "Calibrando el puente, el mecanismo de la rueda y cubriendo la caja.\n[gallery ids=“664,665,666,667,668”]"
  },
  {
    "objectID": "blog/2017-11-09-construyendo-una-zanfona-parte-iv/index.html",
    "href": "blog/2017-11-09-construyendo-una-zanfona-parte-iv/index.html",
    "title": "Construyendo una Zanfona (parte IV)",
    "section": "",
    "text": "El clavijero, mástil y mecanismo\n[gallery ids=“671,672,673,674,675”]"
  },
  {
    "objectID": "blog/2017-11-10-construyendo-una-zanfona-parte-v/index.html",
    "href": "blog/2017-11-10-construyendo-una-zanfona-parte-v/index.html",
    "title": "Construyendo una Zanfona (parte V)",
    "section": "",
    "text": "Terminando el mástil y a puntito para ensamblar todo.\n[gallery ids=“679,680,681,682,683”]"
  },
  {
    "objectID": "blog/2017-11-15-sintesis-de-imagenes-cerebrales-en-python/index.html",
    "href": "blog/2017-11-15-sintesis-de-imagenes-cerebrales-en-python/index.html",
    "title": "Síntesis de imágenes cerebrales en Python",
    "section": "",
    "text": "Acabamos de publicar un nuevo trabajo en Frontiers in Neuroinformatics, en el que probamos el nuevo método que hemos desarrollado para aumentar datos y estandarizar los métodos de evaluación de diferentes sistemas CAD en neuroimagen. Podéis leer el artículo aquí:\nMartinez-Murcia FJ, Górriz JM, Ramírez J, Illán IA, Segovia F, Castillo-Barnes D and Salas-Gonzalez D for the Alzheimer’s Disease Neuroimaging Initiative (2017) Functional Brain Imaging Synthesis Based on Image Decomposition and Kernel Modeling: Application to Neurodegenerative Diseases. Front. Neuroinform. 11:65. doi: 10.3389/fninf.2017.00065\nGrosso modo, nuestro método proyecta las imágenes funcionales al espacio eigenbrain, el espacio PCA definido por los vectores propios de la base de datos. Aquí se modela -según el método utilizado- la distribución de probabilidad que sigue cada uno de los grupos, y una vez se ha generado el modelo, se pueden extraer nuevas muestras aleatorias que sigan esa PDF en el espacio eigenbrain, que luego se pueden retroproyectar al espacio de la imagen. De este modo generamos muestras que pertenecen a la distribución original, pero no son iguales a ella.\n\nEste método está implementado en el paquete brainSimulator, que se puede descargar libremente para su uso en 10.5281/zenodo.1042400, y cuya documentación se puede encontrar aquí: http://brainsimulator.readthedocs.io/.\nPreparar el paquete junto con su documentación, para poder instalarlo con pip o cualquier otro método estándar de instalación en python ha sido otra epopeya, que merece ser contada en otro tiempo y lugar."
  },
  {
    "objectID": "blog/2017-11-21-bohemian-rhapsody/index.html",
    "href": "blog/2017-11-21-bohemian-rhapsody/index.html",
    "title": "Bohemian Rhapsody",
    "section": "",
    "text": "O cómo cumplir uno de los sueños de mi vida.. cantar un musical de Queen. Gracias, cómo siempre, a MusicalArte, y a la Asociación Musical Pep Ventura.\nhttps://www.youtube.com/watch?v=UkaSicgDpVM"
  },
  {
    "objectID": "blog/2018-01-30-jugando-con-logos/index.html",
    "href": "blog/2018-01-30-jugando-con-logos/index.html",
    "title": "Jugando con Logos",
    "section": "",
    "text": "Desde hace tiempo me encargo de parte del diseño gráfico de la asociación Musicalarte, ahora responsabilidad compartida con mi querido Juanemi. Durante el proceso de diseño de algunos carteles, me he encontrado todo tipo de logos de patrocinadores o colaboradores. Particularmente, en el último concierto que dimos con la Asociación Musical Pep Ventura, su logo me dio algún quebradero de cabeza, por su orientación vertical y tipografía delgada. Aquí el logo original:\n\nHe de decir que soy un particular fan de los logos horizontales, y eso me llevó a cuadrarlo de la siguiente forma, para optimizar el espacio:\n\nPierde un poco en legibilidad, pero al menos es facilmente situable. A todo esto, es la versión debidamente vectorizada. Es la versión que finalmente quedó en el cartel. Pero como juego, me propuse darle un aspecto “renovado” a este logo tan icónico de la ciudad sin perder la esencia, que para mi es la información (Asociación Musical Pep Ventura), localización (Alcalá la Real -Jaén-) y el icono de la trompa. Jugando con diversas opciones llegué a un punto que me gustó:\n\nPero de alguna forma no era exactamente lo que me esperaba. Eso sí, tiene un aire interesante para conciertos de música clásica, o incluso un toque a “fundación”. Aún así, la idea de “Asociación musical” predominaba sobre el propio nombre del compositor alcalaíno-catalán del que toma su nombre, a pesar de la negrita. Jugando de nuevo con el logo de la trompa (más solido), llegué a una opción que me encantó:\n\nEstá toda la información presente, mantiene la esencia del logo integrado en el texto, la trompa, y por fin predomina el nombre “Pep Ventura”. Quizá necesita un retoque en las NT, para ganar legibilidad, pero la integración de esta forma me gana bastante, queda coqueto y el ratio de aspecto es adecuado a mi parecer. Por supuesto, son gustos, y esto no es más que un experimento sin validez oficial, pero me gustó el juego de caracteres en general."
  },
  {
    "objectID": "blog/2018-02-26-jupyter-lab/index.html",
    "href": "blog/2018-02-26-jupyter-lab/index.html",
    "title": "Jupyter Lab, un nuevo IDE para python",
    "section": "",
    "text": "Hace un par de semanas se anunció que Jupyter Lab ya está preparado para su uso (aunque todavía en beta). Como no poda ser de otra forma, y presa del ansia viva, fui corriendo a descargar, instalar y probarlo. Pero, ¿qué es Jupyter Lab?\nJupyter es bastante conocido en la comunidad python, desde que hace años apareciese como la evolución de los iPython notebooks, una interfaz amigable de crear “historias” en python, combinando celdas de código y documentación en markdown de una forma muy visual. Desde entonces ha llovido mucho, y, aunque me resultan todavía un poco lentos para trabajar en investigación, sí que los uso en docencia, con bastante buenos resultados.\n[caption id=“attachment_746” align=“alignnone” width=“525”] Interfaz de Jupyter Lab[/caption]\nPues bien, Jupyter Lab es una mezcla de Jupyter + Spyder. Un nuevo IDE basado en web que permite un trabajo bastante cómodo y que, por primera vez, me ha hecho plantearme un nuevo cambio. Tiene edición de código con resaltado, posibilidad de ejecución de varias terminales (kernels de ipython), software inspector y visualización embebida.\nNo es el IDE más completo (de hecho es muy simple), pero su simpleza hace que tenga un gran atractivo. Todavía no sé si se convertirá en mi IDE de cabecera (para mi gusto le falta ejecución por bloques e integración con un debugger), pero tiene muy buena pinta. Y con lo que le queda por delante, puede convertirse en algo mucho más grande."
  },
  {
    "objectID": "blog/2019-02-05-taller-de-comunicacion-3mt/index.html",
    "href": "blog/2019-02-05-taller-de-comunicacion-3mt/index.html",
    "title": "Taller de comunicación 3MT",
    "section": "",
    "text": "El pasado 4 de febrero, mi queridísima compañera en eso de cantar y ganar 3MT, Ana Valverde y un servidor estuvimos impartiendo un taller de comunicación para los nuevos #3Minuters. Hablamos de cómo la interpretación puede ayudar a comunicar el mensaje generando interés y empatía en la audiencia, y abordando diferentes estrategias para lo mismo. Nos centramos en postura, acting y voz, y nos lo pasamos genial con los ejercicios prácticos y los alumnos, enormes, como siempre.\n¡Que tengáis mucha suerte!\nPD: Gracias a Susana y Carlos, como siempre, por contar con nosotros ;)\nUPDATE: Aquí está la presentación que nos curramos (que no nos dio apenas tiempo a ver):\n\n\nY aquí unas fotillos pa alegrar el personal:"
  },
  {
    "objectID": "blog/2019-07-05-la-movilidad-internacional-y-el-sistema-cientifico-espanol/index.html",
    "href": "blog/2019-07-05-la-movilidad-internacional-y-el-sistema-cientifico-espanol/index.html",
    "title": "La movilidad internacional y el sistema científico español",
    "section": "",
    "text": "Hoy me han comunicado que gracias a un real decreto RDA/34097GROMENAGÜER, con el objetivo de favorecer la movilidad internacional, van a reducirme un 20% mi salario a partir del 4º mes que esté fuera. Siempre ayudando a la investigación. Así que me he puesto a escribir y me ha salido un hilo de twitter que reproduzco aquí:"
  },
  {
    "objectID": "blog/2019-07-06-un-proyecto-teuton/index.html",
    "href": "blog/2019-07-06-un-proyecto-teuton/index.html",
    "title": "Un proyecto teutón",
    "section": "",
    "text": "Esta semana he llegado a Munich. Concretamente a la Ludwig-Maximilien Universität München, gracias a la convocatoria nacional de ayudas para la movilidad internacional de jóvenes investigadores “José Castillejo”. Al margen de los problemas con la carrera científica en España, sólo puedo estar agradecido tanto al ministerio de Ciencia como -sobre todo- a mi grupo de investigación por haber conseguido esta ayuda para venir aquí a realizar un proyecto muy, pero que muy, interesante.\n\n\n\n\n\n\n\n\n\n\n¡Oh! ¡Qué intriga! ¿Qué proyecto es? Pues, para volver al redil del Alzheimer, me vengo a Múnich porque es uno de los centros de referencia europeos de la Dominantly Inherited Alzheimer Network (DIAN), una iniciativa destinada a estudiar el Alzheimer hereditario. Al diferencia de lo que mucha gente cree, esta variedad de Alzheimer afecta tan solo a un 1%, pero sus efectos son devastadores. La afección se debe a ciertas variedades de los genes PSEN1, PSEN2 o APP que pasan de padres a hijos con un 50% de probabilidad, provocando que se desarrolle la enfermedad de Alzheimer muy temprano, entre los 30 y los 50 años. Podéis saber más sobre el Alzheimer hereditario en uno de los vídeos divulgativos de DIAN.\nY aquí estoy, dispuesto a aplicar todo lo aprendido durante estos años en uno de los análisis más complejos que voy a realizar, esta vez incluyendo datos de diferentes modalidades de imagen (PET-FDG, PET-PIB y MRI). Probaremos diferentes modelos convolucionales, residuales y otros tipos de arquitecturas de deep learning para tratar de encontrar una descomposición de los datos que permita una interpretación médica del progreso de la enfermedad.\n¿Habrá suerte? Espero que sí. Solo queda trabajar."
  },
  {
    "objectID": "blog/2021-06-08-alcala-la-real-ano-de-construccion-de-edificios/index.html",
    "href": "blog/2021-06-08-alcala-la-real-ano-de-construccion-de-edificios/index.html",
    "title": "Alcalá la Real: año de construcción de edificios",
    "section": "",
    "text": "Hace tiempo vi los mapas que creaba Dominic Royé sobre edad de construcción de edificios, y para los que generó el tutorial de mapas en R.\nEra cuestión de tiempo que, siendo un friki, me pusiera manos a la obra. Y aquí está:\n\nSi lo queréis en mayor resolución (vectorial) aquí está disponible en PDF:\nhttps://doi.org/10.5281/zenodo.4913922"
  },
  {
    "objectID": "blog/2014-09-09-flor-del-cerezo/index.html",
    "href": "blog/2014-09-09-flor-del-cerezo/index.html",
    "title": "Flor del Cerezo",
    "section": "",
    "text": "Decía un tío importante (la verdad es que no lo recuerdo, pero quiero creer que era de la generación del 27) que nunca hay que dejar nada sin publicarse. Así que, aunque haga tiempo que grabé este vídeo, y pese a lo borroso del mismo, hay que tenerlo disponible. A alguien habrá que le guste."
  },
  {
    "objectID": "blog/2014-10-07-monos-en-el-espacio/index.html",
    "href": "blog/2014-10-07-monos-en-el-espacio/index.html",
    "title": "Monos en el Espacio",
    "section": "",
    "text": "Y ya está aquí, por fin, el videoclip de Monos en el Espacio. La última aventura en la que tomé parte junto a Anima Adversa. Y como una imagen vale más que mil palabras, aquí va:\nhttps://www.youtube.com/watch?v=9ru_jC1h32Q\nEl vídeo ha tenido infinidad de detalles, ha tardado más de un año en ver la luz (la primera reunión de concepto fue en Enero de 2013), y ha salido adelante gracias a las ganas, esfuerzo y amor al arte de una gran cantidad de gente.\nEspecialmente, el director, Migue (Enkidu Films) ha sido el que ha sacado adelante este proyecto en el que nadie ha cobrado nada y todo el presupuesto se ha dedicado a pagar las facturas. Desde las reuniones con Lena (que diseñó los trajes de astronauta) o la planificación de la historia con Migue en muuuchos y larguísimos emails hasta la grabación en verano de 2013 (con incidentes incluídos, con una escena que finalmente no ha podido aparecer porque nos quedamos sin plató a mitad de rodaje), apenas soy capaz de recordar los nombres de todos los que han participado.\nTuty y Javi, que asistieron en todo momento a ayudar al director, grandísimos y meticulosos profesionales. Todos los “extras” del vídeo que finalmente han aparecido (Cristina de la Torre, Estela y Cristina Domingo, Inma Pérez) y los que no han podido (Toñín, Iván o Elisa).\nY posteriormente, el trabajo de postproducción, en el que ya yo he estado más desconectado, por mi marcha del grupo. En fin, ha sido una gran aventura y estoy infinitamente agradecido por haber participado en esta obra de arte, y por volver a ser, durante 7 minutos, un adverso más.\n¡Un abrazo a todos!"
  },
  {
    "objectID": "research/2016-09-15-project-sbm/index.html",
    "href": "research/2016-09-15-project-sbm/index.html",
    "title": "Spherical Brain Mapping",
    "section": "",
    "text": "Documentation  Download"
  },
  {
    "objectID": "research/2016-09-15-project-sbm/index.html#project-the-brain.",
    "href": "research/2016-09-15-project-sbm/index.html#project-the-brain.",
    "title": "Spherical Brain Mapping",
    "section": "Project the Brain.",
    "text": "Project the Brain.\n\n\n\nExample of the Projections for White and Grey Matter\n\n\nSpherical Brain Mapping uses an algorithm to perform a projection of the different tissues of the brain to a single plane that can be visually analysed."
  },
  {
    "objectID": "research/2016-09-15-project-sbm/index.html#locate-the-most-signifcant-areas.",
    "href": "research/2016-09-15-project-sbm/index.html#locate-the-most-signifcant-areas.",
    "title": "Spherical Brain Mapping",
    "section": "Locate the most signifcant areas.",
    "text": "Locate the most signifcant areas.\n\n\n\nProjected Atlas of the AAL regions\n\n\nProjected Atlas of the AAL regions It is possible to superimpose a projected brain atlas onto a resulting significance map (e.g., a t-map). Thereby it is easy to identify the sources of the changes in a two-dimensional map."
  },
  {
    "objectID": "research/2016-09-15-project-sbm/index.html#write-your-own-extensions.",
    "href": "research/2016-09-15-project-sbm/index.html#write-your-own-extensions.",
    "title": "Spherical Brain Mapping",
    "section": "Write your own Extensions.",
    "text": "Write your own Extensions.\nSpherical Brain Mapping is written in Matlab, totally compatible with Octave, and ported to Python, so that you can write your own statistical properties to project the brain. The more specific these statistical are, the more significant will be your results."
  },
  {
    "objectID": "teaching/2021-02-13-Quees-un-filtro/index.html",
    "href": "teaching/2021-02-13-Quees-un-filtro/index.html",
    "title": "¿Qué es un filtro?",
    "section": "",
    "text": "Aprovechando la liberación de la librería Manim CE intenté hacer mis pinitos para divulgar qué es un filtro, qué tipos existen y visualizar cómo pasamos de las ecuaciones al efecto que tienen en frecuencia. Tiene la siguiente estructura:\n\n0:00 Introducción\n0:38 Tipos de Filtros\n1:13 Filtro de Paso Baja de primer orden\n1:29 Filtro de Paso Alta de primer orden\n1:46 Filtro de Paso Baja de segundo orden\n2:36 Filtro de Paso Alta de segundo orden\n3:22 Visualización en 3D de la función de transferencia\n\nForma parte de un trabajo iniciado hace un año con el canal de Circuitos y Sistemas de la Universidad de Málaga, y se ha realizado como complemento a un curso de tecnologías y gamificación en el aula realizado en la Universidad de Granada.\n\n\n\nCitationBibTeX citation:@online{martinez-murcia2022,\n  author = {Martinez-Murcia, F.J.},\n  title = {¿Qué Es Un Filtro?},\n  date = {2022-01-02},\n  url = {https://pakitochus.github.io/fjmartinezmurcia.es/teaching/2021-02-13-Quees-un-filtro},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMartinez-Murcia, F.J. 2022. “¿Qué Es Un Filtro?” January 2,\n2022. https://pakitochus.github.io/fjmartinezmurcia.es/teaching/2021-02-13-Quees-un-filtro."
  },
  {
    "objectID": "research/2017-11-30-project-brainsimulator/index.html",
    "href": "research/2017-11-30-project-brainsimulator/index.html",
    "title": "BrainSimulator",
    "section": "",
    "text": "Schema of Brain Simulator\n\n\nbrainSimulator is a brain image synthesis procedure for data augmentation and standardization of evaluation of ML neuroimaging pipelines. It intends to generate a new image set that share characteristics given an original one. The system focuses on nuclear imaging modalities such as PET or SPECT brain images. It analyses the dataset by applying PCA to the original dataset, and then model the distribution of samples in the projected eigenbrain space using a Probability Density Function (PDF) estimator. Once the model has been built, anyone can generate new coordinates on the eigenbrain space belonging to the same class, which can be then projected back to the image space.\n Documentation  Download\n\nInstallation\nbrainSimulator is now available via pypi and can be installed directly from:\npip install brainSimulator\nAlternatively, download the package, uncompress and execute:\ncd /path/to/uncompressed/brainSimulator/\npython setup.py install\n\n\nQuickstart\nThis allows to train the model once and then perform as many sample drawings as required.\n#navigate to the folder where simulator.py is located\nimport brainSimulator as sim\n\nsimulator = sim.BrainSimulator(algorithm='PCA', method='mvnormal')\nsimulator.fit(original_dataset, labels) \nimages, classes = simulator.generateDataset(original_dataset, labels, N=200, classes=[0, 1, 2])\n\n\n\n\nCitationBibTeX citation:@online{martinez-murcia2017,\n  author = {Martinez-Murcia, F.J.},\n  title = {BrainSimulator},\n  date = {2017-11-30},\n  url = {https://pakitochus.github.io/fjmartinezmurcia.es/posts/2017-11-30-project-brainsimulator/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMartinez-Murcia, F.J. 2017. “BrainSimulator.” November 30,\n2017. https://pakitochus.github.io/fjmartinezmurcia.es/posts/2017-11-30-project-brainsimulator/."
  },
  {
    "objectID": "research/2016-10-24-project-swpca/index.html",
    "href": "research/2016-10-24-project-swpca/index.html",
    "title": "Significance Weighted Principal Component Analysis (SWPCA)",
    "section": "",
    "text": "Significance Weighted Principal Component Analysis (SWPCA) is a technique developed to parse out the influence of a categorical variable that introduces variability in a certain dataset (Martinez-Murcia et al. 2017). This was originally intended to remove acquisition site variance in neuroimaging databases.\nDownload the code:  Download\n\nUse\nTo use the script to remove, navigate to the download dir, load the library (import swpca) into your environment and execute this command using the current dataset and acquisition site variables:\nimport swpca\ndataset_rect, weights, A = swpca.swpca(dataset, site)\nIt will return the rectified dataset, to be used in subsequent analysis.\n\n\nAlgorithm Pipeline and Context\nThe main use of the SWPCA algorithm is within the context of common neuroimaging analysis, such as Voxel Based Morphometry (VBM) or a classification analysis. It is a preprocessing step, and as such, it is used just after any other preprocessing steps (such as normalization, etc), and before any further analysis. It provides rectified maps with the influence of the categorical variables removed, therefore decreasing the occurrence of false positives.\n\n\n\nSchema of the SWPCA pipeline\n\n\n\n\n\n\n\nReferences\n\nMartinez-Murcia, Francisco Jesús, Meng-Chuan Lai, Juan Manuel Gorriz, Javier Ramirez, Adam MH Young, Sean CL Deoni, Christine Ecker, et al. 2017. “On the Brain Structure Heterogeneity of Autism: Parsing Out Acquisition Site Effects with Significance-Weighted Principal Component Analysis.” Human Brain Mapping 38 (3): 1208–23.\n\nCitationBibTeX citation:@online{martinez-murcia2016,\n  author = {Martinez-Murcia, F.J.},\n  title = {Significance {Weighted} {Principal} {Component} {Analysis}\n    {(SWPCA)}},\n  date = {2016-10-24},\n  url = {https://pakitochus.github.io/fjmartinezmurcia.es/posts/2016-09-15-project-sbm/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMartinez-Murcia, F.J. 2016. “Significance Weighted Principal\nComponent Analysis (SWPCA).” October 24, 2016. https://pakitochus.github.io/fjmartinezmurcia.es/posts/2016-09-15-project-sbm/."
  },
  {
    "objectID": "research/2017-06-01-phd-thesis/index.html",
    "href": "research/2017-06-01-phd-thesis/index.html",
    "title": "Doctoral Thesis",
    "section": "",
    "text": "This thesis is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. This means that you can download and distribute it as long as you cite the author and do not make money from it.\n Download"
  },
  {
    "objectID": "research/2017-06-01-phd-thesis/index.html#this-thesis-is-copyleft",
    "href": "research/2017-06-01-phd-thesis/index.html#this-thesis-is-copyleft",
    "title": "Doctoral Thesis",
    "section": "",
    "text": "This thesis is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. This means that you can download and distribute it as long as you cite the author and do not make money from it.\n Download"
  },
  {
    "objectID": "research/2017-06-01-phd-thesis/index.html#abstract",
    "href": "research/2017-06-01-phd-thesis/index.html#abstract",
    "title": "Doctoral Thesis",
    "section": "Abstract",
    "text": "Abstract\nThe rise of neuroimaging in the last years has provided physicians and radiologist with the ability to study the brain with unprecedented ease. This led to a new biological perspective in the study of neurodegenerative diseases, allowing the characterization of different anatomical and functional patterns associated with them. Computer Aided Diagnosis (CAD) systems use statistical techniques for preparing, processing and extracting information from neuroimaging data pursuing a major goal: optimize the process of analysis and diagnosis of neurodegenerative diseases and mental conditions.\nWith this thesis we focus on three different stages of the CAD pipeline: preprocessing, feature extraction and validation. For preprocessing, we have developed a method that target a relatively recent concern: the confounding effect of false positives due to differences in the acquisition at multiple sites. Our method can effectively merge datasets while reducing the acquisition site effects. Regarding feature extraction, we have studied decomposition algorithms (independent component analysis, factor analysis), texture features and a complete framework called Spherical Brain Mapping, that reduces the 3-dimensional brain images to two-dimensional statistical maps. This allowed us to improve the performance of automatic systems for detecting Alzheimer’s and Parkinson’s diseases. Finally, we developed a brain image simulation technique that can be used to validate new functional datasets as well as for educational purposes."
  },
  {
    "objectID": "research/2017-06-01-phd-thesis/index.html#slides",
    "href": "research/2017-06-01-phd-thesis/index.html#slides",
    "title": "Doctoral Thesis",
    "section": "Slides",
    "text": "Slides\n    Tesis: Statistical Neuroimage Modeling, Processing and Synthesis based on Texture and Component Analysis  from Francisco Jesús Martínez Murcia"
  },
  {
    "objectID": "research/2023-09-01-project-latidos/index.html",
    "href": "research/2023-09-01-project-latidos/index.html",
    "title": "LATiDOS",
    "section": "",
    "text": "Overview of the LATiDOS methodology\n\n\nLATiDOS is a proposal oriented to solve a particular problem: to create data-driven models of the progression of neurodegeneration and use them to determine the individual age of symptom onset.\n\n\nThe project\nResearch has recently shown that the neuropathological processes of neurodegenerative diseases (NDDs) begin years or even decades before symptoms appear. There are several initiatives worldwide that study the progression of subjects at risk of developing these diseases, some even from a very early age, and that collect a wide variety of longitudinal data such as symptomatology, biochemical markers or neuroimaging. This would provide insight into pathological processes long before their “conversion”, or the appearance of the first symptoms.\nThis proposal aims to combine neuroimaging, biochemical, genetic, neuropsychological and epidemiological data using data fusion and machine learning strategies to study and model the progression of NDDs and predict the individual age of symptom onset. This will be done using feature extraction and fusion methodologies using mainly latent variable models based on deep neural networks. The latent information can be combined with other associated genetic and biochemical data as well as different environmental factors to generate a series of models of NDD progression. Different individual and ensemble models of progression will be proposed, which will be validated qualitatively and quantitatively by experts in statistics and neurology, as well as by assessing their generalisability to other existing databases. On the one hand, it is hoped to obtain a better understanding of the processes of neurodegeneration that will make it possible to characterise the degree of individual affectation at a specific time and how different biological, biochemical and environmental variables affect the speed of progression of the disease. It is also hoped to obtain a computational model to predict the age of symptom onset in individual patients from the above data. On the other hand, significant advances are expected to be made in the study of current deep learning methods applied to medical imaging and data fusion, favouring the paradigm of interpretable machine learning.\n\n\n\nHow a Disease Progression Model (DPM) works.\n\n\n\n\nObjectives\nLATiDOS has one general objective: to build and evaluate data-driven models of the progression of neurodegenerative diseases. These models should be able to determine the individual disease state and progression rate, as well as determining the Age of Symptom Onset (ASO), accounting for variability due to sex, age, etc. This can be realized by achieving the following specific objectives:\n\nDownload, merge and organize a large dataset of NDDs patient data, including medical history, neuroimaging and biomarkers. Modalities include PET-PIB, PET-FDG functional images and Magnetic Resonance Imaging (MRI) -structural and functional-, as well as epidemiological, genetic, biochemical and population data that can help in NDD stratification.\nObtain an accurate and generalizable latent representation of each NDD data cohort with maximum clinical validity. Specific probabilistic neural architectures for manifold learning will be used for this process.\nTo derive causal and non-causal model(s) of DP at different levels of accuracy that primarily use neuroimaging-driven latent variables, but also take into account clinical, environmental and genetic background. Use them to accurately redefine ASO.\nTest and validate the developed models using a diverse set of patients and compare their performance to existing models. Ensure that the DPMs are interpretable by expert neurologists at different levels of accuracy.\nExplore the potential for using these models to identify new biomarkers and drug targets for neurodegenerative diseases.\nInvestigate and communicate the use of these models in clinical settings, such as for early diagnosis and treatment planning. Effective communication of the methodology and results of the project to the scientific community, specialized audience (clinical staff, policymakers, as well as affected subjects and their environment) and the public.\n\n\n\nResults\nThe project is already running and we have several results, e.g.: - A novel framework to evaluate regression performance, called Statistical Agnostic Regression (SAR) (Gorriz et al. 2024).\n\n\n\n\n\nReferences\n\nGorriz, Juan M, J Ramirez, F Segovia, FJ Martinez-Murcia, C Jiménez-Mesa, and J Suckling. 2024. “Statistical Agnostic Regression: A Machine Learning Method to Validate Regression Models.” arXiv Preprint arXiv:2402.15213.\n\nCitationBibTeX citation:@online{martinez-murcia2023,\n  author = {Martinez-Murcia, F.J.},\n  title = {LATiDOS},\n  date = {2023-09-01},\n  url = {https://pakitochus.github.io/research/pakitochus.github.io/research/2023-09-01-project-latidos/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nMartinez-Murcia, F.J. 2023. “LATiDOS.” September 1, 2023.\nhttps://pakitochus.github.io/research/pakitochus.github.io/research/2023-09-01-project-latidos/."
  },
  {
    "objectID": "research/2023-09-01-project-latidos/index.html#disease-course-modelling-of-biomarkers",
    "href": "research/2023-09-01-project-latidos/index.html#disease-course-modelling-of-biomarkers",
    "title": "LATiDOS",
    "section": "Disease course modelling of biomarkers",
    "text": "Disease course modelling of biomarkers\nThe emerging field of DPM offers a way to integrate different types of information, such as imaging, serum, cerebrospinal fluid markers, and cognitive tests, to gain new insights into progressive diseases. These insights include detailed longitudinal patterns of neurodegeneration, from early stages, and the heterogeneity of these trajectories across the population. Practically, such models enable more precise patient staging and stratification, prediction of progression rates, and earlier and better identification of at-risk individuals. DPM might be crucial for recruitment and endpoints in future clinical trials, potentially reducing the high failure rate in trials for NDD therapies.\n\n\n\nHow a Disease Progression Model (DPM) works."
  }
]